<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>9&nbsp; Predict – An Introduction to Quantitative Text Analysis for Linguistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../part_4/10_infer.html" rel="next">
<link href="../part_4/8_explore.html" rel="prev">
<link href="../assets/images/logo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script async="" src="https://hypothes.is/embed.js"></script><script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script><script data-goatcounter="https://italicize.goatcounter.com/count" async="" src="//gc.zgo.at/count.js"></script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="../assets/css/mini.css">
<meta property="og:title" content="9&nbsp; Predict – An Introduction to Quantitative Text Analysis for Linguistics">
<meta property="og:description" content="">
<meta property="og:site_name" content="An Introduction to Quantitative Text Analysis for Linguistics">
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title"><span id="sec-predict-chapter" class="quarto-section-identifier"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Predict</span></span></h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">An Introduction to Quantitative Text Analysis for Linguistics</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/qtalr/book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_0/preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Orientation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_1/1_text.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Text analysis</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/2_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/3_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_2/4_research.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Research</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preparation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/5_acquire.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Acquire</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/6_curate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Curate</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_3/7_transform.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Transform</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/8_explore.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Explore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/9_predict.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Predict</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_4/10_infer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Infer</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../part_5/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Communication</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../part_5/11_contribute.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Contribute</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Contents</h2>
   
  <ul>
<li><a href="#sec-predict-orientation" id="toc-sec-predict-orientation" class="nav-link active" data-scroll-target="#sec-predict-orientation"><span class="header-section-number">9.1</span> Orientation</a></li>
  <li>
<a href="#sec-predict-analysis" id="toc-sec-predict-analysis" class="nav-link" data-scroll-target="#sec-predict-analysis"><span class="header-section-number">9.2</span> Analysis</a>
  <ul class="collapse">
<li><a href="#sec-predict-text-classification" id="toc-sec-predict-text-classification" class="nav-link" data-scroll-target="#sec-predict-text-classification">Text classification</a></li>
  <li><a href="#sec-predict-text-regression" id="toc-sec-predict-text-regression" class="nav-link" data-scroll-target="#sec-predict-text-regression">Text regression</a></li>
  </ul>
</li>
  <li><a href="#activities" id="toc-activities" class="nav-link" data-scroll-target="#activities">Activities</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/qtalr/book/blob/main/part_4/9_predict.qmd" target="_blank" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/qtalr/book/edit/main/part_4/9_predict.qmd" target="_blank" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/qtalr/book/issues" target="_blank" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title d-none d-lg-block"><span id="sec-predict-chapter" class="quarto-section-identifier"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Predict</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-list-alt" aria-label="list-alt"></i> Outcomes</strong></p>
<ul>
<li>Identify the research goals of predictive data analysis</li>
<li>Describe the workflow for predictive data analysis</li>
<li>Recognize quantitative and qualitative methods for evaluating predictive models</li>
</ul>
</div>
</div>
</div>
<p>In this chapter, I introduce supervised learning as an approach to text analysis. Supervised learning aims to establish a relationship between a target (or outcome) variable and a set of feature variables derived from text data. By leveraging this relationship, statistical generalizations (models) can be created to accurately predict values of the target variable based on the values of the feature variables. Throughout the chapter, we explore practical tasks and theoretical applications of statistical learning in text analysis.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-terminal" aria-label="terminal"></i> Lessons</strong></p>
<p><strong>What</strong>: Advanced Visualization<br><strong>How</strong>: In an R console, load {swirl}, run <code>swirl()</code>, and follow prompts to select the lesson.<br><strong>Why</strong>: To dive deeper into {ggplot2} to enhance visual summaries and provide an introduction to {factoextra} and {ggfortify} that extend {ggplot2} capabilities to model objects.</p>
</div>
</div>
</div>
<section id="sec-predict-orientation" class="level2" data-number="9.1"><h2 data-number="9.1" class="anchored" data-anchor-id="sec-predict-orientation">
<span class="header-section-number">9.1</span> Orientation</h2>
<p>Predictive data analysis (PDA) is a powerful analysis method for making predictions about new or future data based on patterns in existing data. PDA is a type of supervised learning, which means that it involves training a model on a labeled dataset where the input data and desired output are both provided. The model is able to make predictions or classifications based on the input data by learning the relationships between the input and output data. Supervised machine learning is an important tool for linguists studying language and communication, as it allows us to analyze language data to identify patterns or trends in language use, assess hypotheses, and prescribe actions.</p>
<p>The approach to conducting predictive analysis shares some commonalities with exploratory data analysis (<a href="8_explore.html#sec-explore-orientation" class="quarto-xref"><span>Section 8.1</span></a>) (as well as inferential analysis <a href="10_infer.html" class="quarto-xref"><span>Chapter 10</span></a>), but there are also some key differences. Consider the workflow in <a href="#tbl-predict-workflow" class="quarto-xref">Table&nbsp;<span>9.1</span></a>.</p>
<!-- Workflow -->
<div id="tbl-predict-workflow" class="quarto-float quarto-figure quarto-figure-center anchored" data-tbl-colwidths="[5, 15, 80]">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-predict-workflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;9.1: Workflow for predictive data analysis
</figcaption><div aria-describedby="tbl-predict-workflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 5%">
<col style="width: 15%">
<col style="width: 80%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;">Step</th>
<th style="text-align: left;">Name</th>
<th style="text-align: left;">Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: left;">Identify</td>
<td style="text-align: left;">Consider the research question and aim and identify relevant variables</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">Split the data into representative training and testing sets</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">Apply variable selection and engineering procedures</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: left;">Inspect</td>
<td style="text-align: left;">Inspect the data to ensure that it is in the correct format and that the training and testing sets are representative of the data</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: left;">Interrogate</td>
<td style="text-align: left;">Train and evaluate the model on the training set, adjusting models or hyperparameters as needed, to produce a final model</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: left;">(Optional) Iterate</td>
<td style="text-align: left;">Repeat steps 3-5 to select new variables, models, hyperparameters</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: left;">Interpret</td>
<td style="text-align: left;">Interpret the results of the final model in light of the research question or hypothesis</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Focusing on the overlap with other analysis methods, we can see some fundamental steps such as identifying relevant variables, inspecting the data, interrogating the data, and interpreting the results. And if our research aim is exploratory in nature, iteration may also be a part of the workflow.</p>
<p>There are two main differences, however, between the PDA and the EDA workflow we discussed in <a href="8_explore.html" class="quarto-xref"><span>Chapter 8</span></a>. The first is that PDA requires partitioning the data into training and testing sets. The training set is used to develop the model, and the testing set is used to evaluate the model’s performance. This strategy is used to ensure that the model is robust and generalizes well to new data. It is well known, and makes intuitive sense, that using the same data to develop and evaluate a model likely will not produce a model that generalizes well to new data. This is because the model will have potentially conflated the nuances of the data (‘the noise’) with any real trends (‘the signal’) and therefore will not be able to generalize well to new data. This is called <strong>overfitting</strong> and by holding out a portion of the data for testing, we can evaluate the model’s performance on data that it has not seen before and therefore get a more accurate estimate of the generalizable trends in the data.</p>
<div class="halfsize callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-medal" aria-label="medal"></i> Dive deeper</strong></p>
<p>Prediction modeling is a hot topic. Given the potential to make actionable predictions about future outcomes, it attracts a lot of attention from organizations which aim to leverage data to make informed decisions. It’s use in research is also growing beyond the development of better models and using predictive models to address research questions and hypotheses.</p>
<p>We will apply predictive modeling in the context of language data as a semi-inductive method. However, it is also increasingly used in hypothesis testing scenarios, see <span class="citation" data-cites="Gries2014">Gries &amp; Deshors (<a href="../references.html#ref-Gries2014" role="doc-biblioref">2014</a>)</span>, <span class="citation" data-cites="Deshors2016">Deshors &amp; Gries (<a href="../references.html#ref-Deshors2016" role="doc-biblioref">2016</a>)</span>, and <span class="citation" data-cites="Baayen2011">Baayen (<a href="../references.html#ref-Baayen2011" role="doc-biblioref">2011</a>)</span> for examples.</p>
</div>
</div>
</div>
<p>Another procedure to avoid the perils of overfitting, is to use resampling methods as part of the model evaluation on the training set. Resampling is the process of repeatedly drawing samples from the training set and evaluating the model on each sample. The two most common resampling methods are <strong>bootstrapping</strong> (resampling with replacement) and <strong>cross-validation</strong> (resampling without replacement). The performance of these multiple models is summarized and the error between them is assessed. The goal is to minimize the performance differences between the models while maximizing the overall performance. These measures go a long way to avoiding overfitting and therefore maximizing the chance that the training phase will produce a model which is robust at the testing phase.</p>
<p>The second difference, not reflected in the workflow but inherent in predictive analysis, is that PDA requires a fixed outcome variable. This means that the outcome variable must be defined from the outset and cannot be changed during the analysis. Furthermore, the informational nature of the outcome variable will dictate what type of algorithm we choose to interrogate the data and how we will evaluate the model’s performance.</p>
<p>If the outcome is categorical in nature, we will use a <strong>classification algorithm</strong> (<em>e.g.</em> logistic regression, naive Bayes, <em>etc.</em>). Classification evaluation metrics include accuracy, precision, recall, and F1 scores (a metric which balances precision and recall) which can be derived from and visualized in a cross-tabulation of the predicted and actual outcome values.</p>
<p>If the outcome is numeric in nature, we will use a <strong>regression algorithm</strong> (<em>e.g.</em> linear regression, support vector regression, <em>etc.</em>). Since the difference between prediction and actual values is numeric, metrics that quantify numerical differences, such as root mean square error (RMSE) or <span class="math inline">\(R^2\)</span>, are used to evaluate the model’s performance.</p>
<p>The evaluation of the model is quantitative on the one hand, but it is also qualitative in that we need to consider the implications of the model’s performance in light of the research question or hypothesis. Furthermore, depending on our research question we may be interested in exploring the features that are most important to the model’s performance. This is called <strong>feature importance</strong> and can be derived from the model’s coefficients or weights. Notably, however, some of the most powerful models in use today, such as deep neural networks, are not easily interpretable and therefore feature importance is not easily derived. This is something to keep in mind when considering the research question and the type of model that will be used to address it.</p>
</section><section id="sec-predict-analysis" class="level2" data-number="9.2"><h2 data-number="9.2" class="anchored" data-anchor-id="sec-predict-analysis">
<span class="header-section-number">9.2</span> Analysis</h2>
<!-- Goals of this section -->
<p>In this section, we now turn to the practical application of predictive data analysis. The discussion will be separated into classification and regression tasks, as model selection and evaluation procedures differ between the two. For each task, we will frame a research goal and work through the process of building a predictive model to address that goal. Along the way we will cover concepts and methods that are common to both classification and regression tasks and specific to each.</p>
<!-- Research questions -->
<p>To frame our analyses, we will posit research aimed at identifying language usage patterns in second language use, one for a classification task and one for a regression task. Our first research question will be to assess whether Spanish language use can be used to predict natives and L1 English learners (categorical). Our second research question will be to gauge the extent to which the L1 English learners’ Spanish language placement test scores (numeric) can be predicted based on their language use.</p>
<div class="cell" data-tbl-colwidths="[15,15,15,55]">
<div id="tbl-predict-cedel2-data-dictionary" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-tbl-colwidths="[15,15,15,55]">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-predict-cedel2-data-dictionary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;9.2: Data dictionary for the CEDEL2 corpus
</figcaption><div aria-describedby="tbl-predict-cedel2-data-dictionary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="cell caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 55%">
</colgroup>
<thead><tr class="header">
<th style="text-align: left;">variable</th>
<th style="text-align: left;">name</th>
<th style="text-align: left;">type</th>
<th style="text-align: left;">description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">doc_id</td>
<td style="text-align: left;">Document ID</td>
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">Unique identifier for each document</td>
</tr>
<tr class="even">
<td style="text-align: left;">subcorpus</td>
<td style="text-align: left;">Subcorpus</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">The sub-corpus to which the document belongs (‘Learner’ or ‘Native’)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">place_score</td>
<td style="text-align: left;">Placement Score</td>
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">The score obtained by the document author in a placement test. Null values indicate missing data (i.e.&nbsp;the document author did not take the placement test)</td>
</tr>
<tr class="even">
<td style="text-align: left;">proficiency</td>
<td style="text-align: left;">Proficiency</td>
<td style="text-align: left;">ordinal</td>
<td style="text-align: left;">The level of language proficiency of the document author (‘Upper intermediate’, ‘Lower advanced’, ‘Upper beginner’, or ‘Native’)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">text</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">character</td>
<td style="text-align: left;">The written text provided by the document author</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>We will use data from the CEDEL2 corpus <span class="citation" data-cites="Lozano2022">(<a href="../references.html#ref-Lozano2022" role="doc-biblioref">Lozano, 2022</a>)</span>. We will include a subset of the variables from this data that are relevant to our research questions. The data dictionary for this dataset is seen in <a href="#tbl-predict-cedel2-data-dictionary" class="quarto-xref">Table&nbsp;<span>9.2</span></a>.</p>
<p>Let’s go ahead and read the transformed dataset and preview it in <a href="#exm-predict-cedel-read" class="quarto-xref">Example&nbsp;<span>9.1</span></a>.</p>
<div id="exm-predict-cedel-read" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.1</strong></span> &nbsp;</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Read in the dataset</span></span>
<span><span class="va">cedel_tbl</span><span class="op">&lt;-</span></span>
<span>  <span class="fu">read_csv</span><span class="op">(</span><span class="st">"../data/cedel2/cedel2_transformed.csv"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="fu">glimpse</span><span class="op">(</span><span class="va">cedel_tbl</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 2,957
Columns: 5
$ doc_id      &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…
$ subcorpus   &lt;chr&gt; "Learner", "Learner", "Learner", "Learner", "Learner", "Le…
$ place_score &lt;dbl&gt; 14.0, 16.3, 16.3, 18.6, 18.6, 18.6, 20.9, 20.9, 20.9, 20.9…
$ proficiency &lt;chr&gt; "Lower beginner", "Lower beginner", "Lower beginner", "Low…
$ text        &lt;chr&gt; "Yo vivo es Alanta, Georgia. Atlanta es muy grande ciudad.…</code></pre>
</div>
</div>
<p> </p>
</div>
<p>The output of <a href="#exm-predict-cedel-read" class="quarto-xref">Example&nbsp;<span>9.1</span></a> provides some structural information about the dataset, number of rows and columns as well as variable types.</p>
<p>After I performed some diagnostics and made some adjustments based on a descriptive assessment, the dataset is in good order to proceed with the analysis. I updated the variables <code>subcorpus</code> and <code>proficiency</code> as factor variables and ordered them in a way that makes sense for the analysis. The <code>place_score</code> variable is distributed well across the proficiency levels. The <code>subcorpus</code> variable is less balanced, with around 65% of the texts being from learners. This is not a problem, but it is something to keep in mind when building and interpreting the predictive models.</p>
<p>We will be using the Tidymodels framework in R to perform these analyses. {tidymodels} is a meta-package, much like {tidyverse}, that provides a consistent interface for machine learning modeling. Some key packages unique to {tidymodels} are {recipes}, {parsnip}, {workflows}, and {tune}. {recipes} includes functions for pre-processing and engineering features. {parsnip} provides a consistent interface for specifying modeling algorithms. {worflows} allows us to combine recipes and models into a single pipeline. Finally, {tune} give us the ability to evaluate and adjust, or ‘tune’, the parameters of models.</p>
<p>Since we are using text data, we will also be using {textrecipes} which makes various functions available for pre-processing text including extracting and engineering features.</p>
<p>Let’s go ahead and do the setup, loading the necessary packages, seen in <a href="#exm-predict-packages-data" class="quarto-xref">Example&nbsp;<span>9.2</span></a>.</p>
<div id="exm-predict-packages-data" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.2</strong></span> &nbsp;</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load packages</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span>   <span class="co"># modeling metapackage</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/tidymodels/textrecipes">textrecipes</a></span><span class="op">)</span>  <span class="co"># text pre-processing</span></span>
<span></span>
<span><span class="co"># Prefer tidymodels functions</span></span>
<span><span class="fu"><a href="https://tidymodels.tidymodels.org/reference/tidymodels_prefer.html">tidymodels_prefer</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p> </p>
</div>
<section id="sec-predict-text-classification" class="level3"><h3 class="anchored" data-anchor-id="sec-predict-text-classification">Text classification</h3>
<!-- Research question: outcome and features -->
<p>The goal of text classification analysis is to develop a model that can accurately label text samples as either native or learner. This is a binary classification problem. We will approach this problem from an exploratory perspective, and therefore our aim is to identify features from the text that best distinguish between the two classes and explore the features that are most important to the model’s performance.</p>
<p>Let’s modify the data frame to include only the variables we need for this analysis, assigning it to <code>cls_tbl</code>. In the process, we will rename the <code>subcorpus</code> variable to <code>outcome</code> to reflect that it is the outcome variable. This is seen in <a href="#exm-predict-class-data" class="quarto-xref">Example&nbsp;<span>9.3</span></a>.</p>
<div id="exm-predict-class-data" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.3</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Rename subcorpus to outcome</span></span>
<span><span class="va">cls_tbl</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">cedel_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">select</span><span class="op">(</span>outcome <span class="op">=</span> <span class="va">subcorpus</span>, <span class="va">proficiency</span>, <span class="va">text</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<!-- Step 1: identify features -->
<p>Let’s begin the workflow from <a href="#tbl-predict-workflow" class="quarto-xref">Table&nbsp;<span>9.1</span></a> by identifying the features that we will use to classify the texts. There may be many features that we could use. These could be features derived from raw text (<em>e.g.</em> characters, words, ngrams, <em>etc.</em>), feature vectors (<em>e.g.</em> word embeddings), or meta-linguistic features (<em>e.g.</em> part-of-speech tags, syntactic parses, or semantic features) that have been derived from these through manual or automatic annotation.</p>
<p>If as part of our research question the types of features are included, then we should proceed toward deriving those features. If not, a simple approach is to use words as the predictor features. This will serve as a baseline for more complex models, if necessary.</p>
<p>This provides us the linguistic unit we will use, but we still need to decide how to operationalize what we mean by ‘use’ in our research statement. Do we use raw token counts? Do we use normalized frequencies? Do we use some type of weighting scheme? These are questions that we need to consider as we embark on this analysis. Since we are exploring, we can use trial-and-error or consider the implications of each approach and choose the one that best fits our research question —or both.</p>
<p>Let’s approach this with a bit more nuance as we already have some domain knowledge about word use. First, we know that the frequency distribution of words is highly skewed, meaning that a few words occur very frequently and most words occur very infrequently. Second, we know that the most frequent words in a language are often function words (<em>e.g.</em> ‘the’, ‘and’, ‘of’, <em>etc.</em>) and that these words are not very informative for distinguishing between classes of texts. Third, we know that comparing raw counts across texts conflates the influence text class lengths.</p>
<p>With these considerations in mind, we will tokenize by words and apply a metric known as the <strong>term-frequency inverse-document frequency</strong> (<span class="math inline">\(tf\)</span>-<span class="math inline">\(idf\)</span>). The <span class="math inline">\(tf\)</span>-<span class="math inline">\(idf\)</span> measure, as the name suggests, is the product of <span class="math inline">\(tf\)</span> and <span class="math inline">\(idf\)</span> for each term. In effect, it produces a weighting scheme, which will downweight words that are common across all documents and upweight words that are unique to a document. It also mitigates the varying lengths of the documents. This is a common approach in text classification and is a good starting point for our analysis.</p>
<!-- Step 2: Initial split -->
<p>With our features and engineering approach identified, we can move on to step 2 of our workflow and split the data into training and testing sets. We make the splits to our data at this point to draw a line in the sand between the data we will use to train the model and the data we will use to test the model. A typical approach in supervised machine learning is to allocate around 75-80% of the data to the training set and the remaining 20-25% to the testing set, depending on the number of observations. We have 2957 observations in our dataset, so we can allocate 80% of the data to the training set and 20% of the data to the testing set.</p>
<p>In <a href="#exm-predict-class-split" class="quarto-xref">Example&nbsp;<span>9.4</span></a>, we will use the <code>initial_split()</code> function from {rsample} to split the data into training and testing sets. The <code>initial_split()</code> function takes a data frame and a proportion and returns a <code>split</code> object which contains the training and testing sets. We will use the <code>strata</code> argument to stratify the data by the <code>outcome</code> variable. This will ensure that the training and testing sets have the same proportion of native and learner texts.</p>
<div style="page-break-after: always;"></div>
<div id="exm-predict-class-split" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.4</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> <span class="co"># for reproducibility</span></span>
<span></span>
<span><span class="co"># Split the data into training and testing sets</span></span>
<span><span class="va">cls_split</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">initial_split</span><span class="op">(</span></span>
<span>    data <span class="op">=</span> <span class="va">cls_tbl</span>,</span>
<span>    prop <span class="op">=</span> <span class="fl">0.8</span>,</span>
<span>    strata <span class="op">=</span> <span class="va">outcome</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># Create training set</span></span>
<span><span class="va">cls_train</span> <span class="op">&lt;-</span> <span class="fu">training</span><span class="op">(</span><span class="va">cls_split</span><span class="op">)</span>  <span class="co"># 80% of data</span></span>
<span></span>
<span><span class="co"># Create testing set</span></span>
<span><span class="va">cls_test</span> <span class="op">&lt;-</span> <span class="fu">testing</span><span class="op">(</span><span class="va">cls_split</span><span class="op">)</span>    <span class="co"># 20% of data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
</div>
<p>A confirmation of the distribution of the data across the training and testing sets as well as a breakdown of the outcome variable, created by {janitor}’s <code>tabyl()</code> function, can be seen in <a href="#exm-predict-class-split-tabyl" class="quarto-xref">Example&nbsp;<span>9.5</span></a>.</p>
<div id="exm-predict-class-split-tabyl" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.5</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># View the distribution</span></span>
<span><span class="co"># Training set</span></span>
<span><span class="va">cls_train</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">tabyl</span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">adorn_totals</span><span class="op">(</span><span class="st">"row"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">adorn_pct_formatting</span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Testing set</span></span>
<span><span class="va">cls_test</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">tabyl</span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">adorn_totals</span><span class="op">(</span><span class="st">"row"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">adorn_pct_formatting</span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> outcome    n percent
 Learner 1524   64.5%
  Native  840   35.5%
   Total 2364  100.0%
 outcome   n percent
 Learner 382   64.4%
  Native 211   35.6%
   Total 593  100.0%</code></pre>
</div>
</div>
<p> </p>
</div>
<p>We can see that the split was successful. The training and testing sets have very similar proportions of native and learner texts.</p>
<!-- Step 3: Integrate: plan to select and engineer features -->
<p>We are now ready to create a ‘recipe’, step 3 in our analysis. A recipe is Tidymodels terminology for a set of instructions or blueprint which specifies the outcome variable and the predictor variable and determines how to pre-process and engineer the feature variables.</p>
<p>We will use the <code><a href="https://recipes.tidymodels.org/reference/recipe.html">recipe()</a></code> function from {recipes} to create the recipe. The <code><a href="https://recipes.tidymodels.org/reference/recipe.html">recipe()</a></code> function minimally takes a formula and a data frame and returns a <code>recipe</code> object. <strong>R formulas</strong> provide a way to specify relationships between variables and are used extensively in R data modeling. Formulas specify the outcome variable (<span class="math inline">\(y\)</span>) and the predictor variable(s) (<span class="math inline">\(x_1 .. x_n\)</span>). For example, <code>y ~ x</code> can be read as “y as a function of x”. In our particular case, we will use the formula <code>outcome ~ text</code> to specify that the outcome variable is the <code>outcome</code> variable and the predictor variable is the <code>text</code> variable. The code is seen in <a href="#exm-predict-class-recipe" class="quarto-xref">Example&nbsp;<span>9.6</span></a>.</p>
<div id="exm-predict-class-recipe" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.6</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create a recipe</span></span>
<span><span class="va">base_rec</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://recipes.tidymodels.org/reference/recipe.html">recipe</a></span><span class="op">(</span></span>
<span>    formula <span class="op">=</span> <span class="va">outcome</span> <span class="op">~</span> <span class="va">text</span>, <span class="co"># formula</span></span>
<span>    data <span class="op">=</span> <span class="va">cls_train</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">base_rec</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
<pre><code>── Recipe ─────────────────────────────────────────

── Inputs
Number of variables by role
outcome:   1
predictor: 1</code></pre>
</div>
<p>The recipe object at this moment contains just one instruction, what the variables are and what their relationship is.</p>
<div class="halfsize callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-hand-point-up" aria-label="hand-point-up"></i> Tip</strong></p>
<p>R formulas are a powerful way to specify relationships between variables and are used extensively in data modeling including exploratory, predictive, and inferential analysis. The basic formula syntax is <code>y ~ x</code> where <code>y</code> is the outcome variable and <code>x</code> is the feature variable. The formula syntax can be extended to include multiple feature variables, interactions, and transformations. For more information on R formulas, see R for Data Science <span class="citation" data-cites="Wickham2017">(<a href="../references.html#ref-Wickham2017" role="doc-biblioref">Wickham &amp; Grolemund, 2017</a>)</span></p>
</div>
</div>
</div>
<p>{recipes} provides a wide range of <code>step_*()</code> functions which can be applied to the recipe to specify how to engineer the variables in our recipe call. These include functions to scale (<em>e.g</em> <code><a href="https://recipes.tidymodels.org/reference/step_center.html">step_center()</a></code>, <code><a href="https://recipes.tidymodels.org/reference/step_scale.html">step_scale()</a></code>, <em>etc.</em>) and transform (<em>e.g.</em> <code><a href="https://recipes.tidymodels.org/reference/step_log.html">step_log()</a></code>, <code><a href="https://recipes.tidymodels.org/reference/step_pca.html">step_pca()</a></code>, <em>etc.</em>) numeric variables, and functions to encode (<em>e.g.</em> <code><a href="https://recipes.tidymodels.org/reference/step_dummy.html">step_dummy()</a></code>, <code>step_labelencode()</code>, <em>etc.</em>) categorical variables.</p>
<p>These step functions are great when we have selected the variables we want to use in our model and we want to engineer them in a particular way. In our case, however, we need to derive features from the text in the <code>text</code> column of datasets before we engineer them.</p>
<p>To ease this process, {textrecipes} provides a number of step functions for pre-processing text data. These include functions to tokenize (<em>e.g.</em> <code><a href="https://textrecipes.tidymodels.org/reference/step_tokenize.html">step_tokenize()</a></code>), remove stop words (<em>e.g.</em> <code><a href="https://textrecipes.tidymodels.org/reference/step_stopwords.html">step_stopwords()</a></code>), and to derive meta-features (<em>e.g.</em> <code><a href="https://textrecipes.tidymodels.org/reference/step_lemma.html">step_lemma()</a></code>, <code><a href="https://textrecipes.tidymodels.org/reference/step_stem.html">step_stem()</a></code>, <em>etc.</em>)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Furthermore, there are functions to engineer features in ways that are particularly relevant to text data, such as feature frequencies and weights (<em>e.g.</em> <code><a href="https://textrecipes.tidymodels.org/reference/step_tf.html">step_tf()</a></code>, <code><a href="https://textrecipes.tidymodels.org/reference/step_tfidf.html">step_tfidf()</a></code>, <em>etc.</em>) and token filtering (<em>e.g.</em> <code><a href="https://textrecipes.tidymodels.org/reference/step_tokenfilter.html">step_tokenfilter()</a></code>).</p>
<div class="halfsize callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-medal" aria-label="medal"></i> Dive deeper</strong> For other tokenization strategies and feature engineering methods, see {textrecipes} documentation <span class="citation" data-cites="R-textrecipes">(<a href="../references.html#ref-R-textrecipes" role="doc-biblioref">Hvitfeldt, 2023</a>)</span>. There are, however, packages which provide integration with <code>textrecipes</code> for other languages, for example, {washoku} for Japanese text processing <span class="citation" data-cites="R-washoku">(<a href="../references.html#ref-R-washoku" role="doc-biblioref">Uryu, 2024</a>)</span>.</p>
</div>
</div>
</div>
<p>So let’s build on our basic recipe <code>cls_rec</code> by adding steps relevant to our task. To extract our features, we will use the <code><a href="https://textrecipes.tidymodels.org/reference/step_tokenize.html">step_tokenize()</a></code> function to tokenize the text into words. The default behavior of the <code><a href="https://textrecipes.tidymodels.org/reference/step_tokenize.html">step_tokenize()</a></code> function is to tokenize the text into words, but other token units can be derived and various options can be added to the function call (as {tokenizers} is used under the hood). Adding the <code><a href="https://textrecipes.tidymodels.org/reference/step_tokenize.html">step_tokenize()</a></code> function to our recipe is seen in <a href="#exm-predict-class-recipe-tokenize" class="quarto-xref">Example&nbsp;<span>9.7</span></a>.</p>
<div id="exm-predict-class-recipe-tokenize" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.7</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Add step to tokenize the text</span></span>
<span><span class="va">cls_rec</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">base_rec</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://textrecipes.tidymodels.org/reference/step_tokenize.html">step_tokenize</a></span><span class="op">(</span><span class="va">text</span><span class="op">)</span> <span class="co"># tokenize</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">cls_rec</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
<pre><code>── Recipe ─────────────────────────────────────────

── Inputs
Number of variables by role
outcome:   1
predictor: 1

── Operations
• Tokenization for: text</code></pre>
</div>
<p>The recipe object <code>cls_rec</code> now contains two instructions, one for the outcome variable and one for the feature variable. The feature variable instruction specifies that the text should be tokenized into words.</p>
<p>We now need to consider how to engineer the word features. If we add <code><a href="https://textrecipes.tidymodels.org/reference/step_tf.html">step_tf()</a></code> we will get a matrix of token counts by default, with the option to specify other weights. The step function <code><a href="https://textrecipes.tidymodels.org/reference/step_tfidf.html">step_tfidf()</a></code> creates a matrix of term frequencies weighted by inverse document frequency.</p>
<p>We decided in step 1 that we will start with <span class="math inline">\(tf\)</span>-<span class="math inline">\(idf\)</span>, so we will add <code><a href="https://textrecipes.tidymodels.org/reference/step_tfidf.html">step_tfidf()</a></code> to our recipe. This is seen in <a href="#exm-predict-class-recipe-tfidf" class="quarto-xref">Example&nbsp;<span>9.8</span></a>.</p>
<div id="exm-predict-class-recipe-tfidf" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.8</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Add step to tokenize the text</span></span>
<span><span class="va">cls_rec</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">cls_rec</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://textrecipes.tidymodels.org/reference/step_tfidf.html">step_tfidf</a></span><span class="op">(</span><span class="va">text</span>, smooth_idf <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">cls_rec</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
<pre><code>── Recipe ─────────────────────────────────────────
Number of variables by role
outcome:   1
predictor: 1

── Operations
• Tokenization for: text
• Term frequency-inverse document frequency with: text</code></pre>
</div>
<!-- Step 4: Inspect:  -->
<!-- [ ] tmp fmt -->
<div style="page-break-after: always;"></div>
<div class="halfsize callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-hand-point-up" aria-label="hand-point-up"></i> Tip</strong></p>
<p>The <code><a href="https://textrecipes.tidymodels.org/reference/step_tfidf.html">step_tfidf()</a></code> function by default adds a <em>smoothing term</em> to the inverse document frequency (<span class="math inline">\(idf\)</span>) calculation. This setting has the effect of reducing the influence of the <span class="math inline">\(idf\)</span> calculation. Thus, terms that appear in many (or all) documents will not be downweighted as much as they would be if the smoothing term was not added. For our purposes, we want to downweight or eliminate the influence of the most frequent terms, so we will set <code>smooth_idf = FALSE</code>.</p>
</div>
</div>
</div>
<p>To make sure things are in order and that the recipe performs as expected, we can use the functions <code><a href="https://recipes.tidymodels.org/reference/prep.html">prep()</a></code> and <code><a href="https://recipes.tidymodels.org/reference/bake.html">bake()</a></code> to inspect the recipe. The <code><a href="https://recipes.tidymodels.org/reference/prep.html">prep()</a></code> function takes a recipe object and a data frame and returns a <code>prep</code> object. The <code>prep</code> object contains the recipe and the data frame with the feature variables engineered according to the recipe. The <code><a href="https://recipes.tidymodels.org/reference/bake.html">bake()</a></code> function takes a <code>prep</code> object and an optional new dataset to apply the recipe to. If we only want to see the application to the training set, we can use the <code>new_data = NULL</code> argument.</p>
<p>In <a href="#exm-predict-class-recipe-prep" class="quarto-xref">Example&nbsp;<span>9.9</span></a>, we use the <code><a href="https://recipes.tidymodels.org/reference/prep.html">prep()</a></code> and <code><a href="https://recipes.tidymodels.org/reference/bake.html">bake()</a></code> functions to create a data frame with the feature variables. We can then inspect the data frame to see if the recipe performs as expected.</p>
<div id="exm-predict-class-recipe-prep" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.9</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Prep and bake</span></span>
<span><span class="va">cls_bake</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">cls_rec</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://recipes.tidymodels.org/reference/prep.html">prep</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># create a prep object</span></span>
<span>  <span class="fu"><a href="https://recipes.tidymodels.org/reference/bake.html">bake</a></span><span class="op">(</span>new_data <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="co"># apply to training set</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">cls_bake</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  2364 38115</code></pre>
</div>
</div>
<p> </p>
</div>
<p>The resulting engineered features data frame has 2,364 observations and 38,115 variables. That is a lot of features! Given the fact that for each writing sample, only a small subset of them will actually appear, most of our cells will be filled with zeros. This is what is known as a <strong>sparse matrix</strong>.</p>
<div class="halfsize callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-hand-point-up" aria-label="hand-point-up"></i> Tip</strong></p>
<p>When applying tokenization and feature engineering steps to text data the result is often contained in a matrix object. Using {recipes} a data frame with a matrix-like structure is returned. Remember, a matrix is a data frame where all the vector types are the same.</p>
<p>Furthermore, the features are prefixed with the variable name and transformation step labels. In <a href="#exm-predict-class-recipe-prep" class="quarto-xref">Example&nbsp;<span>9.9</span></a> we applied <span class="math inline">\(tf\)</span>-<span class="math inline">\(idf\)</span> to the <code>text</code> variable. Therefore the features are prefixed with <code>tfidf_text_</code>.</p>
</div>
</div>
</div>
<p>But we should pause. This is an unwieldy number of features, on for every single word, for a model and it is likely that many of these features are not useful for our classification task. Furthermore, the more features we have, the more chance these features will capture the nuances of these particular writing samples increasing the likelihood we overfit the model. All in all, we need to reduce the number of features.</p>
<p>We can filter out features by stopword list or by frequency of occurrence. Let’s start by frequency of occurrence. We can set the maximum number of the top features with an arbitrary threshold to start. The <code><a href="https://textrecipes.tidymodels.org/reference/step_tokenfilter.html">step_tokenfilter()</a></code> function can filters out features on a number of criteria. Let’s use the <code>max_tokens</code> argument to set the maximum number of features to 100.</p>
<p>This particular step needs to be applied before the <code><a href="https://textrecipes.tidymodels.org/reference/step_tfidf.html">step_tfidf()</a></code> step, so we will add it to our recipe before the <code><a href="https://textrecipes.tidymodels.org/reference/step_tfidf.html">step_tfidf()</a></code> step. This is seen in <a href="#exm-predict-class-recipe-tokenfilter" class="quarto-xref">Example&nbsp;<span>9.10</span></a>.</p>
<div id="exm-predict-class-recipe-tokenfilter" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.10</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Rebuild recipe with tokenfilter step</span></span>
<span><span class="va">cls_rec</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">base_rec</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://textrecipes.tidymodels.org/reference/step_tokenize.html">step_tokenize</a></span><span class="op">(</span><span class="va">text</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://textrecipes.tidymodels.org/reference/step_tokenfilter.html">step_tokenfilter</a></span><span class="op">(</span><span class="va">text</span>, max_tokens <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://textrecipes.tidymodels.org/reference/step_tfidf.html">step_tfidf</a></span><span class="op">(</span><span class="va">text</span>, smooth_idf <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Prep and bake</span></span>
<span><span class="va">cls_bake</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">cls_rec</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://recipes.tidymodels.org/reference/prep.html">prep</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://recipes.tidymodels.org/reference/bake.html">bake</a></span><span class="op">(</span>new_data <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">cls_bake</span><span class="op">)</span></span>
<span></span>
<span><span class="va">cls_bake</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2364  101
# A tibble: 5 × 5
  outcome tfidf_text_a tfidf_text_ahora tfidf_text_al tfidf_text_amigos
  &lt;fct&gt;          &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;
1 Learner      0                      0             0                 0
2 Learner      0.00399                0             0                 0
3 Learner      0.00615                0             0                 0
4 Learner      0                      0             0                 0
5 Learner      0.0111                 0             0                 0</code></pre>
</div>
</div>
<p> </p>
</div>
<p>We now have a manageable set of features, and fewer of which will have a as many zeros. Only during the interrogation step will we know if they are useful.</p>
<div class="halfsize callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-hand-point-up" aria-label="hand-point-up"></i> Tip</strong></p>
<p>The <code><a href="https://recipes.tidymodels.org/reference/prep.html">prep()</a></code> and <code><a href="https://recipes.tidymodels.org/reference/bake.html">bake()</a></code> functions are useful for inspecting the recipe and the engineered features, but they are not required to build a recipe. When a recipe is added to a workflow, the <code><a href="https://recipes.tidymodels.org/reference/prep.html">prep()</a></code> and <code><a href="https://recipes.tidymodels.org/reference/bake.html">bake()</a></code> functions are called automatically as part of the process.</p>
</div>
</div>
</div>
<!-- Step 5: Interrogate -->
<p>We are now ready to turn our attention to step 5 of our workflow, interrogating the data. In this step, we will first select a classification algorithm, then add this algorithm and our recipe to a workflow object. We will then use the workflow object to train and assess the resulting models, adjusting them until we believe we have a robust final model to apply on the testing set for our final evaluation.</p>
<!-- Select a classification algorithm -->
<p>There are many classification algorithms to choose from with their own strengths and shortcomings. In <a href="#tbl-predict-class-algorithms" class="quarto-xref">Table&nbsp;<span>9.3</span></a>, we list some of the most common classification algorithms and their characteristics.</p>
<div id="tbl-predict-class-algorithms" class="quarto-float quarto-figure quarto-figure-center anchored" data-tbl-colwidths="[15, 28, 28, 29]">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-predict-class-algorithms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;9.3: Common classification algorithms
</figcaption><div aria-describedby="tbl-predict-class-algorithms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 28%">
<col style="width: 28%">
<col style="width: 28%">
</colgroup>
<thead><tr class="header">
<th style="text-align: left;">Algorithm</th>
<th style="text-align: left;">Strengths</th>
<th style="text-align: left;">Shortcomings</th>
<th style="text-align: left;">Tuning Recommendation</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Logistic regression</td>
<td style="text-align: left;">Interpretable, fast, high-dimensional data</td>
<td style="text-align: left;">Linear relationship, not for complex tasks</td>
<td style="text-align: left;">Cross-validate regularization strength</td>
</tr>
<tr class="even">
<td style="text-align: left;">Naive Bayes</td>
<td style="text-align: left;">Interpretable, fast, high-dimensional data, multi-class</td>
<td style="text-align: left;">Assumes feature (naive) independence, poor with small data</td>
<td style="text-align: left;">None</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Decision trees</td>
<td style="text-align: left;">Nonlinear, interpretable, numerical/ categorical data</td>
<td style="text-align: left;">Overfitting, high variance</td>
<td style="text-align: left;">Cross-validate maximum tree depth</td>
</tr>
<tr class="even">
<td style="text-align: left;">Random forest</td>
<td style="text-align: left;">Nonlinear, numerical/ categorical data, less overfitting</td>
<td style="text-align: left;">Less interpretable, poor with high-dimensional data</td>
<td style="text-align: left;">Cross-validate number of trees</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Support vector machines</td>
<td style="text-align: left;">Nonlinear, high-dimensional data, numerical/ categorical</td>
<td style="text-align: left;">Requires parameter tuning, memory intensive</td>
<td style="text-align: left;">Cross-validate regularization parameter</td>
</tr>
<tr class="even">
<td style="text-align: left;">Neural networks</td>
<td style="text-align: left;">Nonlinear, large data, auto feature learning</td>
<td style="text-align: left;">Overfitting, difficult to interpret, expensive</td>
<td style="text-align: left;">Cross-validate learning rate</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<!-- Models: simple to complex  -->
<p>In the process of selecting an algorithm, simple, computationally efficient, and interpretable models are preferred over complex, computationally expensive, and uninterpretable models, all things being equal. Only if the performance of the simple model is not good enough should we move on to a more complex model.</p>
<div class="halfsize callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-hand-point-up" aria-label="hand-point-up"></i> Tip</strong></p>
<p>{parsnip} provides a consistent interface to many different models, 105 at the time of writing. You can peruse the list of models by running <code><a href="https://parsnip.tidymodels.org/reference/model_db.html">parsnip::model_db</a></code>.</p>
<p>You can also retrieve the list of potential engines for a given model specification with the <code>show_engines()</code> function. For example, <code>show_engines("logistic_reg")</code> will return a data frame with the engines available for the logistic regression model specification. Note, the engines represent R packages that need to be installed to use the engine.</p>
</div>
</div>
</div>
<p>With this end mind, we will start with a simple logistic regression model to see how well we can classify the texts in the training set with the features we have engineered. We will use the <code>logistic_reg()</code> function from {parsnip} to specify the logistic regression model. We then select the implementation engine (<code>glmnet</code> General Linear Model) and the mode of the model (<code>classification</code>). The implementation engine is the software that will be used to fit the model. The code to set up the model specification is seen in <a href="#exm-predict-class-model-spec" class="quarto-xref">Example&nbsp;<span>9.11</span></a>.</p>
<div id="exm-predict-class-model-spec" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.11</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create a model specification</span></span>
<span><span class="va">cls_spec</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">logistic_reg</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"glmnet"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">cls_spec</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Logistic Regression Model Specification (classification)

Computational engine: glmnet</code></pre>
<p> </p>
</div>
<p>Now, different algorithms will have different parameters that can be adjusted which can affect the performance of the model (see <a href="#tbl-predict-class-algorithms" class="quarto-xref">Table&nbsp;<span>9.3</span></a>). As not to confuse these parameters with the features, which are also parameters of the model, these are given the name <strong>hyperparameters</strong>. The adjustment process is called <strong>hyperparameter tuning</strong> and involves fitting the model to the training set with different hyperparameters and evaluating the model’s performance to determine the best hyperparameter values to use for the model.</p>
<!-- [ ] tmp fmt -->
<div style="page-break-after: always;"></div>
<div class="halfsize callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-hand-point-up" aria-label="hand-point-up"></i> Tip</strong></p>
<p>You can find the hyperparameters for a model-engine by consulting the <code><a href="https://parsnip.tidymodels.org/reference/model_db.html">parsnip::model_db</a></code> object and unnesting the <code>parameters</code> column. For example, <code>parsnip::model_db |&gt; filter(model == "logistic_reg") |&gt; unnest(parameters)</code> will return a data frame with the hyperparameters for the logistic regression model.</p>
<p>To learn more about the hyperparameters for a specific model, you can consult the documentation for <code>parsnip</code> model (<em>e.g.</em> <code>?logistic_reg</code>).</p>
</div>
</div>
</div>
<p>For example, the logistic regression model using <code>glmnet</code> can be tuned to prevent overfitting. The regularization typically applied is the LASSO (L1) penalty<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. The <code>logistic_reg()</code> function takes the arguments <code>penalty</code> and <code>mixture</code>. We set <code>mixture = 1</code>, but we now need to decide what value to use for the strength of the <code>penalty</code> argument. Values can range from 0 to 1, where 0 indicates no penalty and 1 indicates a maximum penalty.</p>
<p>Instead of guessing, we will use {tune} to tune the hyperparameters of the model. The <code>tune()</code> function serves as a placeholder for the hyperparameters we want to tune. We can add the <code>tune()</code> function to our model specification to specify the hyperparameters we want to tune. The code is seen in <a href="#exm-predict-class-model-spec-tune" class="quarto-xref">Example&nbsp;<span>9.12</span></a>.</p>
<div id="exm-predict-class-model-spec-tune" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.12</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create a model specification (with tune)</span></span>
<span><span class="va">cls_spec</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">logistic_reg</span><span class="op">(</span>penalty <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span>, mixture <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"glmnet"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">cls_spec</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Logistic Regression Model Specification (classification)

Main Arguments:
  penalty = tune()
  mixture = 1

Computational engine: glmnet</code></pre>
</div>
<p>We can see now that the <code>cls_spec</code> model specification now includes the <code>tune()</code> function as the value for the <code>penalty</code> argument.</p>
<!-- Combine recipe and model specification -->
<p>To tune our model, we will need to combine our recipe and model specification into a workflow object which sequences our feature selection, engineering, and model selection. We will use the <code>workflow()</code> function from {workflows} to do this. The code is seen in <a href="#exm-predict-class-workflow" class="quarto-xref">Example&nbsp;<span>9.13</span></a>.</p>
<div id="exm-predict-class-workflow" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.13</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create a workflow</span></span>
<span><span class="va">cls_wf</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">cls_rec</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">add_model</span><span class="op">(</span><span class="va">cls_spec</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">cls_wf</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
<pre><code>══ Workflow ═══════════════════════════════════════
Preprocessor: Recipe
Model: logistic_reg()

── Preprocessor ───────────────────────────────────
3 Recipe Steps

• step_tokenize()
• step_tokenfilter()
• step_tfidf()

── Model ──────────────────────────────────────────
Logistic Regression Model Specification (classification)

Main Arguments:
  penalty = tune()
  mixture = 1

Computational engine: glmnet</code></pre>
</div>
<p>We now have a workflow <code>cls_wf</code> that includes our recipe and model specification, including the <code>tune()</code> function as a placeholder for a range of values for the penalty hyperparameter. To tune the penalty hyperparameter, we use the <code>grid_regular()</code> function from {dials} to specify a grid of values to try. Let’s choose a random set of 10 values, as seen in <a href="#exm-predict-class-model-spec-tune-grid-values" class="quarto-xref">Example&nbsp;<span>9.14</span></a>.</p>
<div id="exm-predict-class-model-spec-tune-grid-values" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.14</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create a grid of values for the penalty hyperparameter</span></span>
<span><span class="va">cls_grid</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">grid_regular</span><span class="op">(</span><span class="fu">penalty</span><span class="op">(</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">cls_grid</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 10 × 1
         penalty
           &lt;dbl&gt;
 1 0.0000000001 
 2 0.00000000129
 3 0.0000000167 
 4 0.000000215  
 5 0.00000278   
 6 0.0000359    
 7 0.000464     
 8 0.00599      
 9 0.0774       
10 1            </code></pre>
</div>
</div>
<p> </p>
</div>
<p>The 10 values chosen to be in the grid range from nearly 0 to 1, where 0 indicates no penalty and 1 indicates a strong penalty.</p>
<p>Now to perform the tuning and arrive at an optimal value for <code>penalty</code> we need to create a tuning workflow. We do this by calling the <code>tune_grid()</code> function using our tuning model specification workflow, a resampling object, and our hyperparameter grid and return a <code>tune_grid</code> object.</p>
<p>Resampling is a strategy that allows us to generate multiple training and testing sets from a single dataset —in this case the training data we split at the outset. Each generated training-testing pair is called a fold. Which is why this type of resampling is called <strong>k-fold cross-validation</strong>. The <code>vfold_cv()</code> function from {rsample} takes a data frame and a number of folds and returns a <code>vfold_cv</code> object. We will apply the <code>cls_wf</code> workflow to the 10 folds of the training set with <code>tune_grid()</code>. For each fold, each of the 10 values of the penalty hyperparameter will be tried and the model’s performance will be evaluated. The code is seen in <a href="#exm-predict-class-model-spec-tune-grid-cv" class="quarto-xref">Example&nbsp;<span>9.15</span></a>.</p>
<div id="exm-predict-class-model-spec-tune-grid-cv" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.15</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> <span class="co"># for reproducibility</span></span>
<span></span>
<span><span class="co"># Create a resampling object</span></span>
<span><span class="va">cls_vfold</span> <span class="op">&lt;-</span> <span class="fu">vfold_cv</span><span class="op">(</span><span class="va">cls_train</span>, v <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Tune the model</span></span>
<span><span class="va">cls_tune</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">tune_grid</span><span class="op">(</span></span>
<span>    <span class="va">cls_wf</span>,</span>
<span>    resamples <span class="op">=</span> <span class="va">cls_vfold</span>,</span>
<span>    grid <span class="op">=</span> <span class="va">cls_grid</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">cls_tune</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Tuning results
# 10-fold cross-validation 
# A tibble: 10 × 4
   splits             id     .metrics          .notes          
   &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          
 1 &lt;split [2127/237]&gt; Fold01 &lt;tibble [30 × 5]&gt; &lt;tibble [0 × 3]&gt;
 2 &lt;split [2127/237]&gt; Fold02 &lt;tibble [30 × 5]&gt; &lt;tibble [0 × 3]&gt;
 3 &lt;split [2127/237]&gt; Fold03 &lt;tibble [30 × 5]&gt; &lt;tibble [0 × 3]&gt;
 4 &lt;split [2127/237]&gt; Fold04 &lt;tibble [30 × 5]&gt; &lt;tibble [0 × 3]&gt;
 5 &lt;split [2128/236]&gt; Fold05 &lt;tibble [30 × 5]&gt; &lt;tibble [0 × 3]&gt;
 6 &lt;split [2128/236]&gt; Fold06 &lt;tibble [30 × 5]&gt; &lt;tibble [0 × 3]&gt;
 7 &lt;split [2128/236]&gt; Fold07 &lt;tibble [30 × 5]&gt; &lt;tibble [0 × 3]&gt;
 8 &lt;split [2128/236]&gt; Fold08 &lt;tibble [30 × 5]&gt; &lt;tibble [0 × 3]&gt;
 9 &lt;split [2128/236]&gt; Fold09 &lt;tibble [30 × 5]&gt; &lt;tibble [0 × 3]&gt;
10 &lt;split [2128/236]&gt; Fold10 &lt;tibble [30 × 5]&gt; &lt;tibble [0 × 3]&gt;</code></pre>
</div>
</div>
<p> </p>
</div>
<p>The <code>cls_tune</code> object contains the results of the tuning for each fold. We can see the results of the tuning for each fold by calling the <code>collect_metrics()</code> function on the <code>cls_tune</code> object, as seen in <a href="#exm-predict-class-model-spec-tune-grid-collect" class="quarto-xref">Example&nbsp;<span>9.16</span></a>. Passing the <code>cls_tune</code> object to <code>autoplot()</code> produces the visualization in <a href="#fig-predict-class-model-spec-tune-grid-collect" class="quarto-xref">Figure&nbsp;<span>9.1</span></a>.</p>
<div id="exm-predict-class-model-spec-tune-grid-collect" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.16</strong></span> &nbsp;</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Collect the results of the tuning</span></span>
<span><span class="va">cls_tune_metrics</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">collect_metrics</span><span class="op">(</span><span class="va">cls_tune</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Visualize metrics</span></span>
<span><span class="fu">autoplot</span><span class="op">(</span><span class="va">cls_tune</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-predict-class-model-spec-tune-grid-collect" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Two line plots one showing accuracy and the other showing ROC-AUC for each fold of the tuning process. The y-axis is the metric value and the x-axis is the penalty hyperparameter value.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-predict-class-model-spec-tune-grid-collect-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="9_predict_files/figure-html/fig-predict-class-model-spec-tune-grid-collect-1.png" class="img-fluid figure-img" alt="Two line plots one showing accuracy and the other showing ROC-AUC for each fold of the tuning process. The y-axis is the metric value and the x-axis is the penalty hyperparameter value." width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-predict-class-model-spec-tune-grid-collect-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.1: Metrics for each fold of the tuning process
</figcaption></figure>
</div>
</div>
</div>
<p> </p>
</div>
<p>The most common metrics for model performance in classification are accuracy and the area under the <strong>receiver operating characteristic area under the curve</strong> (ROC-AUC). Accuracy is simply the proportion of correct predictions. The ROC-AUC provides a single score which summarizes how well the model can distinguish between classes. The closer to 1 the more discriminative power the model has.</p>
<p>In the plot of the metrics, <a href="#fig-predict-class-model-spec-tune-grid-collect" class="quarto-xref">Figure&nbsp;<span>9.1</span></a>, we can see that the many of the penalty values performed similarly, with a drop-off in performance at the higher values. Conveniently, the <code>show_best()</code> function from {tune} takes a <code>tune_grid</code> object and returns the best performing hyperparameter values. The code is seen in <a href="#exm-predict-class-model-spec-tune-grid-collect-best" class="quarto-xref">Example&nbsp;<span>9.17</span></a>.</p>
<div id="exm-predict-class-model-spec-tune-grid-collect-best" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.17</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Show the best performing hyperparameter value</span></span>
<span><span class="va">cls_tune</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">show_best</span><span class="op">(</span>metric <span class="op">=</span> <span class="st">"roc_auc"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 7
        penalty .metric .estimator  mean     n std_err .config              
          &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                
1 0.000464      roc_auc binary     0.952    10 0.00487 Preprocessor1_Model07
2 0.00599       roc_auc binary     0.952    10 0.00344 Preprocessor1_Model08
3 0.0000000001  roc_auc binary     0.951    10 0.00502 Preprocessor1_Model01
4 0.00000000129 roc_auc binary     0.951    10 0.00502 Preprocessor1_Model02
5 0.0000000167  roc_auc binary     0.951    10 0.00502 Preprocessor1_Model03</code></pre>
</div>
</div>
<p> </p>
</div>
<p>We can make this selection programmatically by using the <code>select_best()</code> function. This function needs a metric to select by. We will use the ROC-AUC and select the best value for the penalty hyperparameter. The code is seen in <a href="#exm-predict-class-model-spec-tune-grid-collect-select" class="quarto-xref">Example&nbsp;<span>9.18</span></a>.</p>
<div style="page-break-after: always;"></div>
<div id="exm-predict-class-model-spec-tune-grid-collect-select" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.18</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Select the best performing hyperparameter value</span></span>
<span><span class="va">cls_best</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">select_best</span><span class="op">(</span><span class="va">cls_tune</span>, metric <span class="op">=</span> <span class="st">"roc_auc"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">cls_best</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
   penalty .config              
     &lt;dbl&gt; &lt;chr&gt;                
1 0.000464 Preprocessor1_Model07</code></pre>
</div>
</div>
<p> </p>
</div>
<p>All of that to tune a hyperparameter! Now we can update the model specification and workflow with the best performing hyperparameter value using the previous <code>cls_wf_tune</code> workflow and the <code>finalize_workflow()</code> function. The <code>finalize_workflow()</code> function takes a workflow and the selected parameters and returns an updated <code>workflow</code> object, as seen in <a href="#exm-predict-class-tune-hyperparameters-update-workflow" class="quarto-xref">Example&nbsp;<span>9.19</span></a>.</p>
<div id="exm-predict-class-tune-hyperparameters-update-workflow" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.19</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Update model specification</span></span>
<span><span class="va">cls_wf_lasso</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">cls_wf</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">finalize_workflow</span><span class="op">(</span><span class="va">cls_best</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">cls_wf_lasso</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
<pre><code>══ Workflow ═══════════════════════════════════════
Preprocessor: Recipe
Model: logistic_reg()

── Preprocessor ───────────────────────────────────

• step_tokenize()
• step_tokenfilter()
• step_tfidf()

── Model ──────────────────────────────────────────
Logistic Regression Model Specification (classification)

Main Arguments:
  penalty = 0.000464158883361278
  mixture = 1

Computational engine: glmnet</code></pre>
</div>
<p>Our model specification and the workflow are updated with the tuned hyperparameter.</p>
<p>As a reminder, we are still working in step 5 of our workflow, interrogating the data. So far, we have selected and engineered the features, split the data into training and testing sets, and selected a classification algorithm. We have also tuned the hyperparameters of the model and updated the model specification and workflow with the best performing hyperparameter value.</p>
<p>The next step is to assess the performance of the model on the training set given the features we have engineered, the algorithm we have selected, and the hyperparameters we have tuned. Instead of evaluating the model on the training set directly, we will use cross-validation on the training set to gauge the variability of the model.</p>
<p>The reason for this is that the model’s performance on the entire training set at once is not a reliable indicator of the model’s performance on new data —just imagine if you were to take the same test over and over again, you would get better and better at the test, but that doesn’t mean you’ve learned the material any better. Cross-validation is a technique that allows us to estimate the model’s performance on new data by simulating the process of training and testing the model on different subsets of the training data.</p>
<p>Similar to what we did to tune the hyperparameters, we can use cross-validation to gauge the variability of the model. The <code>fit_resamples()</code> function takes a workflow and a resampling object and returns metrics for each fold. The code is seen in <a href="#exm-predict-class-tune-hyperparameters-evaluate-workflow-cv" class="quarto-xref">Example&nbsp;<span>9.20</span></a>.</p>
<div id="exm-predict-class-tune-hyperparameters-evaluate-workflow-cv" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.20</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Cross-validate workflow</span></span>
<span><span class="va">cls_lasso_cv</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">cls_wf_lasso</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">fit_resamples</span><span class="op">(</span></span>
<span>    resamples <span class="op">=</span> <span class="va">cls_vfold</span>,</span>
<span>    <span class="co"># save predictions for confusion matrix</span></span>
<span>    control <span class="op">=</span> <span class="fu">control_resamples</span><span class="op">(</span>save_pred <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
</div>
<p>We want to aggregate the metrics across the folds to get a sense of the variability of the model. The <code>collect_metrics()</code> function takes the results of a cross-validation and returns a data frame with the metrics.</p>
<div style="page-break-after: always;"></div>
<div id="exm-predict-class-tune-hyperparameters-evaluate-workflow-cv-collect" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.21</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Collect metrics</span></span>
<span><span class="fu">collect_metrics</span><span class="op">(</span><span class="va">cls_lasso_cv</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 6
  .metric     .estimator   mean     n std_err .config             
  &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
1 accuracy    binary     0.884     10 0.00554 Preprocessor1_Model1
2 brier_class binary     0.0823    10 0.00385 Preprocessor1_Model1
3 roc_auc     binary     0.952     10 0.00487 Preprocessor1_Model1</code></pre>
</div>
</div>
</div>
<p>From the accuracy and ROC-AUC metrics in <a href="#exm-predict-class-tune-hyperparameters-evaluate-workflow-cv-collect" class="quarto-xref">Example&nbsp;<span>9.21</span></a> it appears we have a decent candidate model, but there is room for potential improvement. A good next step is to evaluate the model errors and see if there are any patterns that can be addressed before considering what approach to take to improve the model.</p>
<div class="halfsize callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-hand-point-up" aria-label="hand-point-up"></i> Tip</strong></p>
<p>To provide context in terms of what is a good model performance, it is useful to compare the model’s performance to a null model. A <strong>null model</strong> (or baseline model) is a simple model that is easy to implement and provides a benchmark for the model’s performance. For classification tasks, a common null model is to predict the most frequent class. In modeling, this is the minimal benchmark we want to beat, if we are doing better than this, we are doing better than chance.</p>
</div>
</div>
</div>
<p>For classification tasks, a good place to start is to visualize a confusion matrix. A <strong>confusion matrix</strong> is a cross-tabulation of the predicted and actual outcomes. The <code>conf_mat_resampled()</code> function takes a <code>fit_resamples</code> object (with predictions saved) and returns a table (<code>tidy = FALSE</code>) with the confusion matrix for the aggregated folds. We can pass this to the <code>autoplot()</code> function to plot as in <a href="#exm-predict-class-tune-hyperparameters-evaluate-workflow-cv-confusion" class="quarto-xref">Example&nbsp;<span>9.22</span></a>.</p>
<div id="exm-predict-class-tune-hyperparameters-evaluate-workflow-cv-confusion" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.22</strong></span> &nbsp;</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot confusion matrix</span></span>
<span><span class="va">cls_lasso_cv</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">conf_mat_resampled</span><span class="op">(</span>tidy <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">autoplot</span><span class="op">(</span>type <span class="op">=</span> <span class="st">"heatmap"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p> </p>
</div>
<div id="fig-class-tune-hyperparameters-evaluate-workflow-cv-confusion" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Heatmap of the confusion matrix for the aggregated folds of the cross-validation. Actual classes are on the y-axis and predicted classes are on the x-axis.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-class-tune-hyperparameters-evaluate-workflow-cv-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/fig-class-tune-hyperparameters-evaluate-workflow-cv-confusion.png" class="img-fluid figure-img" style="width:55.0%" alt="Heatmap of the confusion matrix for the aggregated folds of the cross-validation. Actual classes are on the y-axis and predicted classes are on the x-axis.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-tune-hyperparameters-evaluate-workflow-cv-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.2: Confusion matrix for the aggregated folds of the cross-validation
</figcaption></figure>
</div>
<p>The top left to bottom right diagonal contains the true positives and true negatives. These are the correct predictions. The top right to bottom left diagonal contains the false positives and false negatives —our errors. The convention is to speak of one class being the positive class and the other class being the negative class. In our case, we will consider the positive class to be the ‘learner’ class and the negative class to be the ‘natives’ class.</p>
<p>We can see that there are more learners falsely predicted to be natives than the other way around. This may be due to the fact that there are simply more learners than natives in the dataset or this could signal that there are some learners that are more similar to natives than other learners. Clearly this can’t be the entire explanation as the model is not perfect, even some natives are classified falsely as learners! But it may be an interesting avenue for further exploration. Perhaps these are learners that are more advanced or have a particular style of writing that is more similar to natives.</p>
<div class="halfsize callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-medal" aria-label="medal"></i> Dive deeper</strong></p>
<p>Another perspective often applied to evaluate a model is the receiver operating characteristic (ROC) curve. The ROC curve is a plot of the true positive rate (TPR) against the false positive rate (FPR) for different classification thresholds. This metric, and visualization, can be useful to gauge the model’s ability to distinguish between the two classes. {yardstick} provides the <code>roc_curve()</code> function to calculate the ROC curve on an <code>fit_resamples</code> object.</p>
</div>
</div>
</div>
<!-- Model improvement: tune max tokens -->
<p>To improve supervised learning models, consider:</p>
<ol type="1">
<li>Engineering the features differently</li>
<li>Selecting different (or additional) features</li>
<li>Changing the algorithm</li>
<li>Tuning the hyperparameters differently</li>
</ol>
<p>Of these options, adjusting the feature engineering process is the option that diverges least from our current workflow <code>cls_wf_lasso</code>. Recall that in our recipe specification we set a token filter to limit the number of features to 100. We can adjust this number to see if it has an effect on the model’s performance.</p>
<p>To help select the optimal number of tokens, we again can use the tuning process we explored for the hyperparameters. This time, however, the <code>tune()</code> placeholder will be included as the argument to the <code>max_tokens</code> argument in the <code><a href="https://textrecipes.tidymodels.org/reference/step_tokenfilter.html">step_tokenfilter()</a></code> function.</p>
<p>I repeat the recipe with the tuning placeholder in <a href="#exm-predict-class-tune-hyperparameters-tokenfilter" class="quarto-xref">Example&nbsp;<span>9.23</span></a>.</p>
<div id="exm-predict-class-tune-hyperparameters-tokenfilter" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.23</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create a recipe with a token filter step</span></span>
<span><span class="va">cls_rec</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://recipes.tidymodels.org/reference/recipe.html">recipe</a></span><span class="op">(</span></span>
<span>    formula <span class="op">=</span> <span class="va">outcome</span> <span class="op">~</span> <span class="va">text</span>,</span>
<span>    data <span class="op">=</span> <span class="va">cls_train</span></span>
<span>    <span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://textrecipes.tidymodels.org/reference/step_tokenize.html">step_tokenize</a></span><span class="op">(</span><span class="va">text</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://textrecipes.tidymodels.org/reference/step_tokenfilter.html">step_tokenfilter</a></span><span class="op">(</span><span class="va">text</span>, max_tokens <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://textrecipes.tidymodels.org/reference/step_tfidf.html">step_tfidf</a></span><span class="op">(</span><span class="va">text</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
</div>
<p>With the updated recipe, we can update the <code>cls_wf_lasso</code> and tune the <code>max_tokens</code> hyperparameter. The code is seen in <a href="#exm-predict-class-tune-hyperparameters-update-rec" class="quarto-xref">Example&nbsp;<span>9.24</span></a>.</p>
<div id="exm-predict-class-tune-hyperparameters-update-rec" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.24</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Update workflow with token filter tuning</span></span>
<span><span class="va">cls_wf_lasso</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">cls_wf_lasso</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">update_recipe</span><span class="op">(</span><span class="va">cls_rec</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
</div>
<p>One thing to note is that we will want to consider what values of <code>max_tokens</code> we want to use to tune the hyperparameter. So instead of only specifying the levels in the <code>grid_regular()</code> function, we are best off to provide a range of values that we think are reasonable. Let’s add a range of values between our current value 100 and 2,000 to start. And let’s tell the grid to select five values from this range.</p>
<p>The code is seen in <a href="#exm-predict-class-tune-hyperparameters-tokenfilter-grid" class="quarto-xref">Example&nbsp;<span>9.25</span></a>.</p>
<div style="page-break-after: always;"></div>
<div id="exm-predict-class-tune-hyperparameters-tokenfilter-grid" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.25</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create a grid of values for the max tokens hyperparameter</span></span>
<span><span class="va">cls_grid</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">grid_regular</span><span class="op">(</span><span class="fu">max_tokens</span><span class="op">(</span>range <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">2000</span><span class="op">)</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">cls_grid</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 1
  max_tokens
       &lt;int&gt;
1        100
2        575
3       1050
4       1525
5       2000</code></pre>
</div>
</div>
<p> </p>
</div>
<p>From here, the process is the same as before. We will use the <code>tune_grid()</code> function to tune the <code>max_tokens</code> hyperparameter, select the best value, and finalize the workflow, as seen from <a href="#exm-predict-class-model-spec-tune-grid-cv" class="quarto-xref">Example&nbsp;<span>9.15</span></a> through <a href="#exm-predict-class-tune-hyperparameters-update-workflow" class="quarto-xref">Example&nbsp;<span>9.19</span></a>.</p>
<p>After tuning the <code>max_tokens</code> hyperparameter, the best performing value is 1,050. We now used the updated <code>cls_wf_lasso_tokens</code> workflow to cross-validate the model and collect the metrics. The code is seen in <a href="#exm-predict-class-tune-hyperparameters-tokenfilter-evaluate-workflow-cv-collect" class="quarto-xref">Example&nbsp;<span>9.26</span></a>.</p>
<div id="exm-predict-class-tune-hyperparameters-tokenfilter-evaluate-workflow-cv-collect" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.26</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Cross-validate workflow</span></span>
<span><span class="va">cls_lasso_tokens_cv</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">cls_wf_lasso_tokens</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">fit_resamples</span><span class="op">(</span></span>
<span>    resamples <span class="op">=</span> <span class="va">cls_vfold</span>,</span>
<span>    <span class="co"># save predictions for confusion matrix</span></span>
<span>    control <span class="op">=</span> <span class="fu">control_resamples</span><span class="op">(</span>save_pred <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># Collect metrics</span></span>
<span><span class="fu">collect_metrics</span><span class="op">(</span><span class="va">cls_lasso_tokens_cv</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 6
  .metric     .estimator   mean     n std_err .config             
  &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
1 accuracy    binary     0.918     10 0.00555 Preprocessor1_Model1
2 brier_class binary     0.0680    10 0.00418 Preprocessor1_Model1
3 roc_auc     binary     0.968     10 0.00289 Preprocessor1_Model1</code></pre>
</div>
</div>
<p> </p>
</div>
<p>The metrics from <a href="#exm-predict-class-tune-hyperparameters-tokenfilter-evaluate-workflow-cv-collect" class="quarto-xref">Example&nbsp;<span>9.26</span></a> show that the model’s performance has improved for both the accuracy and the ROC-AUC. The confusion matrix from <a href="#exm-predict-class-tune-hyperparameters-tokenfilter-evaluate-workflow-cv-confusion" class="quarto-xref">Example&nbsp;<span>9.27</span></a> shows that the number of false positives and false negatives has decreased. This is a good sign that the model is more robust.</p>
<!--TODO: Issue with the sizing of the heatmap(s)-->
<div id="exm-predict-class-tune-hyperparameters-tokenfilter-evaluate-workflow-cv-confusion" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.27</strong></span> &nbsp;</p>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot confusion matrix</span></span>
<span><span class="va">cls_lasso_tokens_cv</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">conf_mat_resampled</span><span class="op">(</span>tidy <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">autoplot</span><span class="op">(</span>type <span class="op">=</span> <span class="st">"heatmap"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p> </p>
</div>
<div id="fig-predict-class-tune-hyperparameters-tokenfilter-evaluate-workflow-cv-confusion" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Heatmap of the confusion matrix for the aggregated folds of the cross-validation. Actual classes are on the y-axis and predicted classes are on the x-axis.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-predict-class-tune-hyperparameters-tokenfilter-evaluate-workflow-cv-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/fig-predict-class-tune-hyperparameters-tokenfilter-evaluate-workflow-cv-confusion.png" class="img-fluid figure-img" style="width:55.0%" alt="Heatmap of the confusion matrix for the aggregated folds of the cross-validation. Actual classes are on the y-axis and predicted classes are on the x-axis.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-predict-class-tune-hyperparameters-tokenfilter-evaluate-workflow-cv-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.3: Confusion matrix for the aggregated folds of the cross-validation
</figcaption></figure>
</div>
<p>From <a href="#fig-predict-class-tune-hyperparameters-tokenfilter-evaluate-workflow-cv-confusion" class="quarto-xref">Figure&nbsp;<span>9.3</span></a>, it appears that the model is more robust with the updated <code>max_tokens</code> hyperparameter. We could continue to explore other model improvement strategies, but for now we will move on to the next step in our workflow.</p>
<!-- Step 6: Evaluate -->
<p>We are now ready to move on to step 7, evaluating the model on the test set. To do this we need to fit the tuned workflow to the training set, which is the actual training phase. We will use the <code>last_fit()</code> function from {workflows} to fit the workflow to the training set.</p>
<p>The <code>last_fit()</code> function takes a workflow and a split object and returns a <code>last_fit</code> object. The <code>last_fit</code> object contains the results of the model fit on the training set and the results of the model evaluation on the test set. The code is seen in <a href="#exm-predict-class-tune-hyperparameters-evaluate-test" class="quarto-xref">Example&nbsp;<span>9.28</span></a>.</p>
<p>We will use the <code>last_fit()</code> function to train the final model and predict the outcome on the test set. The <code>collect_metrics()</code> function takes a data frame with the actual and predicted outcomes and returns a data frame with the metrics for the model. The code is seen in <a href="#exm-predict-class-tune-hyperparameters-evaluate-test" class="quarto-xref">Example&nbsp;<span>9.28</span></a>.</p>
<div id="exm-predict-class-tune-hyperparameters-evaluate-test" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.28</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Fit the model to the training set and evaluate on the test set</span></span>
<span><span class="va">cls_final_fit</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">last_fit</span><span class="op">(</span></span>
<span>    <span class="va">cls_wf_lasso_tokens</span>,</span>
<span>    split <span class="op">=</span> <span class="va">cls_split</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># Evaluate model on testing set</span></span>
<span><span class="fu">collect_metrics</span><span class="op">(</span><span class="va">cls_final_fit</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 4
  .metric     .estimator .estimate .config             
  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 accuracy    binary        0.909  Preprocessor1_Model1
2 roc_auc     binary        0.962  Preprocessor1_Model1
3 brier_class binary        0.0758 Preprocessor1_Model1</code></pre>
</div>
</div>
<p> </p>
</div>
<p>The performance metrics are very close to those we achieved on the training set in <a href="#exm-predict-class-tune-hyperparameters-tokenfilter-evaluate-workflow-cv-collect" class="quarto-xref">Example&nbsp;<span>9.26</span></a>. This is a good sign that the model is robust as it performs well on both training and test sets. We can evaluate the confusion matrix on the test set as well. The code is seen in <a href="#exm-predict-class-tune-hyperparameters-evaluate-test-confusion" class="quarto-xref">Example&nbsp;<span>9.29</span></a> and the visualization in <a href="#fig-class-tune-hyperparameters-evaluate-workflow-cv-confusion" class="quarto-xref">Figure&nbsp;<span>9.4</span></a>.</p>
<div id="exm-predict-class-tune-hyperparameters-evaluate-test-confusion" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.29</strong></span> &nbsp;</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot confusion matrix</span></span>
<span><span class="va">cls_final_fit</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">collect_predictions</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">conf_mat</span><span class="op">(</span>truth <span class="op">=</span> <span class="va">outcome</span>, estimate <span class="op">=</span> <span class="va">.pred_class</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">autoplot</span><span class="op">(</span>type <span class="op">=</span> <span class="st">"heatmap"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p> </p>
</div>
<div id="fig-class-tune-hyperparameters-evaluate-workflow-cv-confusion" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Heatmap of the confusion matrix for the test set. Actual classes are on the y-axis and predicted classes are on the x-axis.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-class-tune-hyperparameters-evaluate-workflow-cv-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/fig-predict-class-tune-hyperparameters-evaluate-test-confusion.png" class="img-fluid figure-img" style="width:55.0%" alt="Heatmap of the confusion matrix for the test set. Actual classes are on the y-axis and predicted classes are on the x-axis.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-class-tune-hyperparameters-evaluate-workflow-cv-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.4: Confusion matrix for the test set
</figcaption></figure>
</div>
<p>On the test set the false instances are balanced, which is a good sign that the model is robust. Ideally, there would be no errors, but this is not realistic. The model is not perfect, but it is useful.</p>
<p>Now a model that can predict the nativeness of a writer based on their writing sample is a useful tool in itself. You could imagine that this could be a pre-processing step for a language learning application, for example. But for a study that is more interested in learning about what features are most important for predicting the native versus non-native features of a writer, we still have some work to do. We can inspect the errors on the test set to gain some insight into what writing samples, and which proficiency levels of the writers, are most difficult to predict. We can also inspect the estimates for the features in the model to gain some insight into what features are most important for predicting the outcomes.</p>
<p>Let’s first approach this from a document-proficiency point of view. First, we will want to integrate the predictions with the test set to inspect the errors. We can use the <code>collect_predictions()</code> function to collect the predictions from the <code>last_fit</code> object and attach them with the test set <code>cls_test</code> with <code>bind_cols</code>. Note, we can drop the <code>outcome</code> variable from <code>cls_test</code> as we have this column in our fitted model. The code is seen in <a href="#exm-predict-class-tune-hyperparameters-integrate-test" class="quarto-xref">Example&nbsp;<span>9.30</span></a>.</p>
<div id="exm-predict-class-tune-hyperparameters-integrate-test" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.30</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Collect predictions from the model</span></span>
<span><span class="va">cls_lasso_fit_preds_test</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">cls_final_fit</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">collect_predictions</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">bind_cols</span><span class="op">(</span><span class="va">cls_test</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="fu">glimpse</span><span class="op">(</span><span class="va">cls_lasso_fit_preds_test</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 593
Columns: 9
$ .pred_class   &lt;fct&gt; Learner, Learner, Learner, Native, Learner, Learner, Lea…
$ .pred_Learner &lt;dbl&gt; 1.0000, 1.0000, 1.0000, 0.0996, 1.0000, 0.9928, 1.0000, …
$ .pred_Native  &lt;dbl&gt; 9.59e-06, 1.13e-05, 3.16e-09, 9.00e-01, 2.83e-06, 7.17e-…
$ id            &lt;chr&gt; "train/test split", "train/test split", "train/test spli…
$ .row          &lt;int&gt; 3, 7, 15, 21, 22, 25, 36, 43, 47, 50, 53, 57, 62, 66, 68…
$ outcome       &lt;fct&gt; Learner, Learner, Learner, Learner, Learner, Learner, Le…
$ .config       &lt;chr&gt; "Preprocessor1_Model1", "Preprocessor1_Model1", "Preproc…
$ proficiency   &lt;fct&gt; Lower beginner, Lower beginner, Lower beginner, Lower be…
$ text          &lt;chr&gt; "Sanaa Lathan es muy famosa persona. Ella es en de telev…</code></pre>
</div>
</div>
<p> </p>
</div>
<p>I will then select the columns with the actual outcome, the predicted outcome, the proficiency level, and the text and separate the predicted outcome to inspect them separately, as seen in <a href="#exm-predict-class-tune-hyperparameters-evaluate-test-errors" class="quarto-xref">Example&nbsp;<span>9.31</span></a>.</p>
<div id="exm-predict-class-tune-hyperparameters-evaluate-test-errors" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.31</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Inspect errors</span></span>
<span><span class="va">cls_lasso_fit_preds_test</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">outcome</span> <span class="op">!=</span> <span class="va">.pred_class</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">outcome</span>, <span class="va">.pred_class</span>, <span class="va">proficiency</span>, <span class="va">text</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 54 × 4
   outcome .pred_class proficiency        text                                  
   &lt;fct&gt;   &lt;fct&gt;       &lt;fct&gt;              &lt;chr&gt;                                 
 1 Learner Native      Lower beginner     "Un día un pequeño nino fue dado una …
 2 Learner Native      Upper beginner     "Un dia, El niño estaba durmiendo cua…
 3 Learner Native      Upper beginner     "Yo vivo en la ciudad de Atlanta. En …
 4 Learner Native      Upper beginner     "Hola me llamo Jason.\n Mis amigos es…
 5 Learner Native      Lower intermediate "Recientemente vi una película que es…
 6 Learner Native      Upper intermediate "Vivo en la ciudad de Richmond en Vir…
 7 Learner Native      Upper intermediate "A la semana pasada, yo vi la pelicul…
 8 Learner Native      Upper intermediate "Un día decidí llevarme a casa una ra…
 9 Learner Native      Lower advanced     "Bueno, el año pasado mi novia y yo v…
10 Learner Native      Lower advanced     "Un día Pablo, un niño de 6 años, enc…
# ℹ 44 more rows</code></pre>
</div>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Inspect learners falsely predicted to be natives</span></span>
<span><span class="va">cls_lasso_fit_preds_test</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">outcome</span> <span class="op">==</span> <span class="st">"Learner"</span>, <span class="va">.pred_class</span> <span class="op">==</span> <span class="st">"Native"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">outcome</span>, <span class="va">.pred_class</span>, <span class="va">proficiency</span>, <span class="va">text</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">count</span><span class="op">(</span><span class="va">proficiency</span>, sort <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 2
  proficiency            n
  &lt;fct&gt;              &lt;int&gt;
1 Upper advanced        10
2 Lower advanced         9
3 Upper beginner         3
4 Upper intermediate     3
5 Lower beginner         1
6 Lower intermediate     1</code></pre>
</div>
</div>
<p> </p>
</div>
<p>Interestingly, the majority of misclassified learners are advanced, which could be expected as they are more similar to natives. There are some beginners that are misclassified as natives, but this is not as common. Yes, it is still an open question as to why some natives are classified as learners.</p>
<p>We can inspect the estimates for the features in the model to gain some insight into what features are most important for predicting the outcomes. The <code>extract_fit_parsnip()</code> function takes a trained model specification <code>cls_final_fit</code> and returns a data frame with the estimated coefficients for each feature. The code is seen in <a href="#exm-predict-class-tune-hyperparameters-evaluate-test-estimates" class="quarto-xref">Example&nbsp;<span>9.32</span></a>.</p>
<div id="exm-predict-class-tune-hyperparameters-evaluate-test-estimates" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.32</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Extract estimates</span></span>
<span><span class="va">cls_final_fit_features</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">cls_final_fit</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">extract_fit_parsnip</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
</div>
<p>The estimates are the log odds of the outcome. In a binary classification task, the log odds of the outcome is the log of the probability of the outcome divided by the probability of the other outcome. In our case, the reference outcome is “Learner”, so negative log-odds indicate that the feature is associated with the “Learner” outcome and positive log-odds indicate that the feature is associated with the “Native” outcome.</p>
<p>The estimates are in log-odds, so we need to exponentiate them to get the odds. The odds are the probability of the outcome divided by the probability of the other outcome. The probability of the outcome is the odds divided by the odds plus one. The code is seen in <a href="#exm-predict-class-tune-hyperparameters-evaluate-test-estimates-probability" class="quarto-xref">Example&nbsp;<span>9.33</span></a>.</p>
<div style="page-break-after: always;"></div>
<div id="exm-predict-class-tune-hyperparameters-evaluate-test-estimates-probability" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.33</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate probability</span></span>
<span><span class="va">cls_final_fit_features</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>probability <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">estimate</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">estimate</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1,051 × 4
   term                  estimate  penalty probability
   &lt;chr&gt;                    &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;
 1 (Intercept)             -13.6  0.000464  0.00000129
 2 tfidf_text_10             0    0.000464  0.5       
 3 tfidf_text_2              0    0.000464  0.5       
 4 tfidf_text_3              0    0.000464  0.5       
 5 tfidf_text_4              0    0.000464  0.5       
 6 tfidf_text_5              0    0.000464  0.5       
 7 tfidf_text_a             64.9  0.000464  1         
 8 tfidf_text_abandonado     7.02 0.000464  0.999     
 9 tfidf_text_abuela        -8.64 0.000464  0.000176  
10 tfidf_text_abuelos        2.14 0.000464  0.895     
# ℹ 1,041 more rows</code></pre>
</div>
</div>
<p> </p>
</div>
<p>So just looking at the snippet of the features returned from <a href="#exm-predict-class-tune-hyperparameters-evaluate-test-estimates-probability" class="quarto-xref">Example&nbsp;<span>9.33</span></a>, we can see that the features ‘a’ and ‘abandonado’ are associated with the “Native” outcome, ‘abuela’ is associated with “Learners”, and the other features are neutral (<code>probability</code> = 0.5).</p>
<p>A quick way to extract the most important features for predicting each outcome is to use the <code><a href="https://koalaverse.github.io/vip/reference/vi.html">vi()</a></code> function from {vip}. It takes a trained model specification and returns a data frame with the most important features. The code is seen in <a href="#exm-predict-class-tune-hyperparameters-evaluate-test-vip" class="quarto-xref">Example&nbsp;<span>9.34</span></a>.</p>
<div id="exm-predict-class-tune-hyperparameters-evaluate-test-vip" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.34</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/koalaverse/vip/">vip</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Avoid conflicts for function names from other packages</span></span>
<span><span class="fu">conflicted</span><span class="fu">::</span><span class="fu"><a href="https://conflicted.r-lib.org/reference/conflicts_prefer.html">conflicts_prefer</a></span><span class="op">(</span><span class="fu">vip</span><span class="fu">::</span><span class="va"><a href="https://koalaverse.github.io/vip/reference/vi.html">vi</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Extract important features</span></span>
<span><span class="va">var_importance_tbl</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">cls_final_fit</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">extract_fit_parsnip</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://koalaverse.github.io/vip/reference/vi.html">vi</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">var_importance_tbl</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1,050 × 3
   Variable           Importance Sign 
   &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;
 1 tfidf_text_época         354. POS  
 2 tfidf_text_mayoría       320. NEG  
 3 tfidf_text_ésta          312. POS  
 4 tfidf_text_ante          278. POS  
 5 tfidf_text_proximo       274. NEG  
 6 tfidf_text_esperar       245. NEG  
 7 tfidf_text_mucha         244. NEG  
 8 tfidf_text_seguir        242. POS  
 9 tfidf_text_poder         241. POS  
10 tfidf_text_ahí           235. POS  
# ℹ 1,040 more rows</code></pre>
</div>
</div>
<p> </p>
</div>
<p>The <code>Variable</code> column contains each feature (with the feature type and corresponding variable <code>tfidf_text_</code>), <code>Importance</code> provides the absolute log-odds value, and the <code>Sign</code> column indicates whether the feature is associated with the “NEG” (“Learner”) or the “POS” (“Native”) outcome. We can recode the <code>Variable</code> and <code>Sign</code> columns to make them more interpretable and then plot them using <code>ggplot()</code>, as in <a href="#exm-predict-class-tune-hyperparameters-evaluate-test-vip-plot" class="quarto-xref">Example&nbsp;<span>9.35</span></a>.</p>
<div id="exm-predict-class-tune-hyperparameters-evaluate-test-vip-plot" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.35</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Recode variable and sign</span></span>
<span><span class="va">var_importance_tbl</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">var_importance_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span></span>
<span>    Feature <span class="op">=</span> <span class="fu">str_remove</span><span class="op">(</span><span class="va">Variable</span>, <span class="st">"tfidf_text_"</span><span class="op">)</span>,</span>
<span>    Outcome <span class="op">=</span> <span class="fu">case_when</span><span class="op">(</span></span>
<span>      <span class="va">Sign</span> <span class="op">==</span> <span class="st">"NEG"</span> <span class="op">~</span> <span class="st">"Learner"</span>,</span>
<span>      <span class="va">Sign</span> <span class="op">==</span> <span class="st">"POS"</span> <span class="op">~</span> <span class="st">"Native"</span><span class="op">)</span>,</span>
<span>    <span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">Outcome</span>, <span class="va">Feature</span>, <span class="va">Importance</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot</span></span>
<span><span class="va">var_importance_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_max</span><span class="op">(</span><span class="va">Importance</span>, n <span class="op">=</span> <span class="fl">50</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/reorder.factor.html">reorder</a></span><span class="op">(</span><span class="va">Feature</span>, <span class="va">Importance</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">Importance</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">coord_flip</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span> <span class="va">Outcome</span>, scales <span class="op">=</span> <span class="st">"free_y"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="cn">NULL</span>, y <span class="op">=</span> <span class="st">"Importance"</span>, fill <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-predict-class-tune-hyperparameters-evaluate-test-vip-plot" class="quarto-float quarto-figure quarto-figure-center anchored" alt="scatterplot of the most important features for predicting the outcome. The y-axis is the importance value and the x-axis is the feature. The features are faceted by the outcome.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-predict-class-tune-hyperparameters-evaluate-test-vip-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="9_predict_files/figure-html/fig-predict-class-tune-hyperparameters-evaluate-test-vip-plot-1.png" class="img-fluid figure-img" alt="scatterplot of the most important features for predicting the outcome. The y-axis is the importance value and the x-axis is the feature. The features are faceted by the outcome." width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-predict-class-tune-hyperparameters-evaluate-test-vip-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.5: Most important features for predicting the outcome
</figcaption></figure>
</div>
</div>
</div>
<p> </p>
</div>
<p>We can inspect <a href="#fig-predict-class-tune-hyperparameters-evaluate-test-vip-plot" class="quarto-xref">Figure&nbsp;<span>9.5</span></a>, and qualitatively assess what these features may be telling us about the differences between the learners and the natives.</p>
<p>In this section, we’ve build a text classifier using a regularized logistic regression model. We’ve tuned the hyperparameters to arrive at a robust model that performs well on both the training and test sets. We’ve also evaluated the model errors and inspected the most important features for predicting the outcome.</p>
</section><section id="sec-predict-text-regression" class="level3"><h3 class="anchored" data-anchor-id="sec-predict-text-regression">Text regression</h3>
<p>We will now turn our attention to the second task in this section, text regression. In this task, we will use the same original dataset as in the classification task, but we will predict the placement score based on the learner writing samples. I will make reference to but not repeat the steps we took in the classification task, as many of the steps are the same. This is one of the benefits of using Tidymodels—the workflow is by-and-large the same for different tasks.</p>
<p>Let’s start by extracting the observations (only learners) and the relevant variables from the original dataset. The code is seen in <a href="#exm-predict-reg-data" class="quarto-xref">Example&nbsp;<span>9.36</span></a>.</p>
<div id="exm-predict-reg-data" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.36</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Extract observations and relevant variables</span></span>
<span><span class="va">reg_tbl</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">cedel_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">subcorpus</span> <span class="op">==</span> <span class="st">"Learner"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">select</span><span class="op">(</span>outcome <span class="op">=</span> <span class="va">place_score</span>, <span class="va">proficiency</span>, <span class="va">text</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="fu">glimpse</span><span class="op">(</span><span class="va">reg_tbl</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 1,906
Columns: 3
$ outcome     &lt;dbl&gt; 14.0, 16.3, 16.3, 18.6, 18.6, 18.6, 20.9, 20.9, 20.9, 20.9…
$ proficiency &lt;fct&gt; Lower beginner, Lower beginner, Lower beginner, Lower begi…
$ text        &lt;chr&gt; "Yo vivo es Alanta, Georgia. Atlanta es muy grande ciudad.…</code></pre>
</div>
</div>
<p> </p>
</div>
<!-- Step 1: Identify variables -->
<p>In this task, our outcome variable is numeric and our predictor variable <code>text</code> is the same as before. It might be useful to engineer the features differently, but we will start with the same feature engineering process as before, namely the <span class="math inline">\(tf\)</span>-<span class="math inline">\(idf\)</span> method for the top 1,050 words.</p>
<!-- Step 2: Initial split -->
<!-- Step 3: Create recipe -->
<!-- Step 4: Verify recipe -->
<p>I create a data split, <code>reg_split</code> and the training and testing sets, <code>reg_train</code> and <code>reg_test</code> and create a <code>reg_rec</code> recipe object which contains the starting recipe for the regression task. And, since we are using the same recipe as before, there is no need to validate the recipe. We can skip straight to the model building.</p>
<!-- Step 5: Interrogate -->
<p>As before, we will want to start with a simple model and then build up to more complex models. The list in <a href="#tbl-predict-class-algorithms" class="quarto-xref">Table&nbsp;<span>9.3</span></a>, includes algorithms that are commonly used in classification tasks. Interestingly, many of these same algorithms can be applied to regression. One exception is that instead of logistic regression, linear regression is used for numeric outcomes. As with logistic regression, linear regression model is one of the simpler models. And just as with logistic regression, we will want to tune the regularization hyperparameter of the linear regression model. Instead of detailing these steps again, let me summarize the process, in <a href="#tbl-workflow" class="quarto-xref">Table&nbsp;<span>9.4</span></a>, and then we will discuss the results from the regularized linear regression model.</p>
<div id="tbl-workflow" class="quarto-float quarto-figure quarto-figure-center anchored" data-tbl-colwidths="[5, 95]">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-workflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;9.4: Steps to build and tune a model
</figcaption><div aria-describedby="tbl-workflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 5%">
<col style="width: 95%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;">Step</th>
<th style="text-align: left;">Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: left;">Build a model specification with a placeholder to tune the model.</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: left;">Create a workflow with the recipe and the model specification.</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: left;">Create a grid of values for the regularization hyperparameter.</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: left;">Tune the model using cross-validation.</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: left;">Select the best performing hyperparameter value (based on RMSE).</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: left;">Update the model specification and workflow with the best performing hyperparameter value.</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: left;">Fit the model to the training set and evaluate the performance using cross-validation.</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Applying the steps 1 through 7, we have cross-validated results for our model in the <code>reg_lasso_cv</code> object. We can collect the relevant metrics, root mean squared error (RMSE) and R-squared (<span class="math inline">\(R^2\)</span>) values. Let’s aggregate these measures using the code is seen in <a href="#exm-predict-reg-metrics-lasso" class="quarto-xref">Example&nbsp;<span>9.37</span></a>.</p>
<div id="exm-predict-reg-metrics-lasso" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.37</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Collect metrics</span></span>
<span><span class="fu">collect_metrics</span><span class="op">(</span><span class="va">reg_lasso_cv</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 6
  .metric .estimator   mean     n std_err .config             
  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
1 rmse    standard   14.1      10  0.269  Preprocessor1_Model1
2 rsq     standard    0.621    10  0.0119 Preprocessor1_Model1</code></pre>
</div>
</div>
<p> </p>
</div>
<p>Now, the <strong>root mean squared error</strong> (RMSE) estimate is 14.1. RMSE is a measure of the difference between the predicted and the actual values expressed in the same units as the outcome variable. In this case, the outcome variable is the placement test score percent. So the RMSE is 14.1 percentage points. <strong>R-squared</strong> (<span class="math inline">\(R^2\)</span>) is a measure of the proportion of the variance in the outcome variable that is explained by the model. The <span class="math inline">\(R^2\)</span> estimate is 0.621. This means that the model explains 62% of the variance in the outcome variable. Taken together, this isn’t the greatest model.</p>
<p>But how good or bad is it? This is where we can use the null model to compare the model to. The null model is a model that predicts the mean of the outcome variable for each of the outcomes. We can use the <code>null_model()</code> function to create a null model and submit it to cross-validation, <a href="#exm-predict-reg-model-spec-tune-fit-evaluate-null" class="quarto-xref">Example&nbsp;<span>9.38</span></a>.</p>
<div id="exm-predict-reg-model-spec-tune-fit-evaluate-null" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.38</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create null model</span></span>
<span><span class="va">null_model</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">null_model</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"parsnip"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Cross-validate null model</span></span>
<span><span class="va">null_cv</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">reg_rec</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">add_model</span><span class="op">(</span><span class="va">null_model</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">fit_resamples</span><span class="op">(</span></span>
<span>    resamples <span class="op">=</span> <span class="fu">vfold_cv</span><span class="op">(</span><span class="va">reg_train</span>, v <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>,</span>
<span>    metrics <span class="op">=</span> <span class="fu">metric_set</span><span class="op">(</span><span class="va">rmse</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># Collect metrics</span></span>
<span><span class="fu">collect_metrics</span><span class="op">(</span><span class="va">null_cv</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 6
  .metric .estimator  mean     n std_err .config             
  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
1 rmse    standard    22.6    10   0.203 Preprocessor1_Model1</code></pre>
</div>
</div>
<p> </p>
</div>
<div class="halfsize callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-exclamation-triangle" aria-label="exclamation-triangle"></i> Warning</strong></p>
<p>For model specifications in which the model can be used in a classification or regression task, the model specification must be set to the correct mode before fitting the model. We have not set the mode for the <code>logistic_reg()</code> or <code>linear_reg()</code> model specifications, as the task is inferred. However, we have set the mode for the <code>null_model()</code>, and other model specifications that can be used in both classification and regression tasks.</p>
</div>
</div>
</div>
<p>Our regression model performs better than the null model (22.6), which means that it is picking up on some signal in the data.</p>
<p>Let’s visualize the distribution of the predictions and the errors from our model to see if there are any patterns of interest. We can use the <code>collect_predictions()</code> function to extract the predictions of the cross-validation and plot the true outcome against the predicted outcome using <code>ggplot()</code>, as in <a href="#exm-predict-reg-lr-eval-rmse" class="quarto-xref">Example&nbsp;<span>9.39</span></a>.</p>
<!--TODO: add theme_qtalr-->
<div id="exm-predict-reg-lr-eval-rmse" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.39</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Visualize predictions</span></span>
<span><span class="va">reg_lasso_cv</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">collect_predictions</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">outcome</span>, <span class="va">.pred</span>, shape <span class="op">=</span> <span class="va">id</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.5</span>, position <span class="op">=</span> <span class="fu">position_jitter</span><span class="op">(</span>width <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span>, linewidth <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span> <span class="co"># trend for each fold</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Truth"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Predicted score"</span>,</span>
<span>    shape <span class="op">=</span> <span class="st">"Fold"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-predict-reg-lr-eval-rmse" class="quarto-float quarto-figure quarto-figure-center anchored" alt="scatterplot of the true outcome against the predicted outcome for the cross-validated linear regression model. The x-axis is the true outcome and the y-axis is the predicted outcome. The shape of the points indicate the fold.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-predict-reg-lr-eval-rmse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="9_predict_files/figure-html/fig-predict-reg-lr-eval-rmse-1.png" class="img-fluid figure-img" alt="scatterplot of the true outcome against the predicted outcome for the cross-validated linear regression model. The x-axis is the true outcome and the y-axis is the predicted outcome. The shape of the points indicate the fold." width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-predict-reg-lr-eval-rmse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.6: Distribution of the RMSE for the cross-validated linear regression model
</figcaption></figure>
</div>
</div>
</div>
<p> </p>
</div>
<p>From <a href="#fig-predict-reg-lr-eval-rmse" class="quarto-xref">Figure&nbsp;<span>9.6</span></a>, we see data points for each predicted and truth value pair for each of the ten folds. There is a trend line for each fold which shows the linear relationship between the predicted and truth values for each fold. The trend lines are more similar than different, which is a good sign that the model is not wildly overfitting the training data. Looking closer, however, we can see the errors. Some are noticeably distant from the linear trend lines, <em>i.e.</em> outliers, in particular for test scores in the lower ranges.</p>
<p>If the <span class="math inline">\(R^2\)</span> value is in the ballpark, this means that somewhere around 40% of the variation is not explained by the frequency of the top 1,050 words. This is not surprising, as there are many other factors that contribute to the proficiency level of a text.</p>
<p>We have a model that is performing better than the null model, but it is not performing well enough to be very useful. We will need to update the model specification and/ or the features to try to improve the model fit. Let’s start with the model. There are many different model specifications we could try, but we will likely need to use a more complex model specification to capture the complexity that we observe in the errors from the current linear regression model.</p>
<p>Let’s try a decision tree model. <strong>Decision trees</strong> are models that are able to model nonlinear relationships and interactions between the features and the outcome and tend to be less influenced by outliers. Furthermore, decision trees are interpretable, which is a nice feature for an exploratory-oriented analysis. These are all desirable characteristics. Decision trees, however, can be prone to overfitting. For this reason, we will tune the maximum depth of the tree to minimize overfitting.</p>
<p>To implement a new model in Tidymodels, we need to create a new model specification and a new workflow. We will use the <code>decision_tree()</code> function from {parsnip} to create the model specification. The <code>decision_tree()</code> function takes a <code>tree_depth</code> argument that we want to tune. We create the new model specification with the tuning placeholder in <a href="#exm-predict-reg-model-spec-decision-tree" class="quarto-xref">Example&nbsp;<span>9.40</span></a>.</p>
<div id="exm-predict-reg-model-spec-decision-tree" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.40</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create model specification</span></span>
<span><span class="va">reg_spec</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">decision_tree</span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"rpart"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">reg_spec</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
<pre><code>Decision Tree Model Specification (regression)

Main Arguments:
  tree_depth = tune()

Computational engine: rpart</code></pre>
</div>
<p>With the model and tuning specification in place, we can now continue through the steps outlined in <a href="#tbl-workflow" class="quarto-xref">Table&nbsp;<span>9.4</span></a> for this decision tree model. To create the grid of values for the tree depth hyperparameter, we will include the <code>grid_regular()</code> function with 10 levels, as seen in <a href="#exm-predict-reg-decision-tree-depth" class="quarto-xref">Example&nbsp;<span>9.41</span></a>.</p>
<div id="exm-predict-reg-decision-tree-depth" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.41</strong></span> Tuning values for the tree depth hyperparameter</p>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">reg_grid</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">grid_regular</span><span class="op">(</span><span class="fu">tree_depth</span><span class="op">(</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p> </p>
</div>
<p>We can collect the metrics and inspect the RMSE and <span class="math inline">\(R^2\)</span> values. The code is seen in <a href="#exm-predict-reg-metrics-tree" class="quarto-xref">Example&nbsp;<span>9.42</span></a>.</p>
<div id="exm-predict-reg-metrics-tree" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.42</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Collect metrics</span></span>
<span><span class="fu">collect_metrics</span><span class="op">(</span><span class="va">reg_tree_cv</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 6
  .metric .estimator   mean     n std_err .config             
  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
1 rmse    standard   15.9      10  0.256  Preprocessor1_Model1
2 rsq     standard    0.510    10  0.0210 Preprocessor1_Model1</code></pre>
</div>
</div>
<p></p>
</div>
<p>The performance for the decision tree is worse than the regularized linear regression model. The RMSE is 15.9 and the <span class="math inline">\(R^2\)</span> is 0.51. And, if we compare the standard error between the two models, we can see that the decision tree model has a lower standard error. This means that the decision tree model is likely overfitting, despite our efforts to tune tree depth.</p>
<p>Given the sensitivity of the decision tree branching process and random initialization, it is possible that the decision tree model is capturing too much nuance, and not enough generalities. Re-running the model with a different seed may result in a different model. This is a limitation with decision tree models, but it is also a feature, if we consider combining multiple decision trees to make a prediction. This is the basis of <strong>ensemble models</strong>. An ensemble model is a model that combines multiple models with the goal to draw out the strengths of each model and minimize the weaknesses.</p>
<p>A <strong>random forest</strong> is an ensemble model that combines multiple decision trees to make a prediction. In addition, random forests also perform random feature selection. This helps to reduce the correlation between the decision trees and thus works to reduce the overall variance of the model.</p>
<p>Let’s try a random forest model to address our text regression task. We will use the <code>rand_forest()</code> function from {parsnip} to create the model specification. The <code>rand_forest()</code> function also takes a hyperparameter for the number of trees to be used in the model. We will select the <code>ranger</code> engine. Additionally, we will add the <code>importance</code> argument to ensure that we can extract feature importance if this model proves to be useful. We create the new model specification in <a href="#exm-predict-reg-model-spec-random-forest" class="quarto-xref">Example&nbsp;<span>9.43</span></a>.</p>
<div id="exm-predict-reg-model-spec-random-forest" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.43</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create model specification</span></span>
<span><span class="va">reg_spec</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">rand_forest</span><span class="op">(</span>trees <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"ranger"</span>, importance <span class="op">=</span> <span class="st">"impurity"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">reg_spec</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Random Forest Model Specification (regression)

Main Arguments:
  trees = tune()

Engine-Specific Arguments:
  importance = impurity

Computational engine: ranger</code></pre>
<p> </p>
</div>
<div class="halfsize callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-lightbulb" aria-label="lightbulb"></i> Consider this</strong></p>
<p>The model building process is iterative and many of the steps are the same. This is a good indication that creating a custom function to build and tune the model would be a good idea.</p>
<p>Consider the following: What would you include in the function? What would you leave out? What required and/ or optional arguments would you include? What would you hard code? What would you return?</p>
</div>
</div>
</div>
<p>Again, we apply the steps in <a href="#tbl-workflow" class="quarto-xref">Table&nbsp;<span>9.4</span></a> to build and tune the random forest model. As part of this process, I will limit the range of the number of trees from 100 to 500 in five levels in the tuning grid, as seen in <a href="#exm-predict-reg-random-forest-trees" class="quarto-xref">Example&nbsp;<span>9.44</span></a>.</p>
<div id="exm-predict-reg-random-forest-trees" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.44</strong></span> Tuning values for the number of trees hyperparameter</p>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">reg_grid</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">grid_regular</span><span class="op">(</span><span class="fu">trees</span><span class="op">(</span>range <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">500</span><span class="op">)</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s collect the metrics and inspect the RMSE and <span class="math inline">\(R^2\)</span> values. The code is seen in <a href="#exm-predict-reg-metrics-rf" class="quarto-xref">Example&nbsp;<span>9.45</span></a>.</p>
<div id="exm-predict-reg-metrics-rf" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.45</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Collect metrics</span></span>
<span><span class="fu">collect_metrics</span><span class="op">(</span><span class="va">reg_rf_cv</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 6
  .metric .estimator   mean     n std_err .config             
  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
1 rmse    standard   12.9      10  0.320  Preprocessor1_Model1
2 rsq     standard    0.697    10  0.0164 Preprocessor1_Model1</code></pre>
</div>
</div>
<p> </p>
</div>
<p>The random forest model performs better than the decision tree model and the regularized linear regression model. The RMSE is 12.9 and the <span class="math inline">\(R^2\)</span> is 0.697. We also see that the standard error falls between the models we have tried so far.</p>
<p>Before we settle on this model, let’s try one more model. In this case, we will introduce a neural network model. <strong>Neural networks</strong> are models that are able to model nonlinear relationships and interactions between the features and the outcome. They are also able to model complex relationships between the features and the outcome. We will use the <code>mlp()</code> function from {parsnip} to create the model specification. We will choose the <code>brulee</code> engine which allows us to tune the learning rate. The learning rate is a hyperparameter that controls the size of the steps that the model takes to update the weights during training.</p>
<div class="halfsize callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-exclamation-triangle" aria-label="exclamation-triangle"></i> Warning</strong></p>
<p>The <code>brulee</code> engine requires that the Torch computing resources are available on the computing environment. To facilitate the installation, {torch} provides the <code>install_torch()</code> function. This is a one-time operation. From this point on, R packages which depend on Torch will be able to take advantage of this rich machine learning framework.</p>
</div>
</div>
</div>
<p>We create the new model specification with the tuning placeholder in <a href="#exm-predict-reg-model-spec-mlp" class="quarto-xref">Example&nbsp;<span>9.46</span></a>.</p>
<div id="exm-predict-reg-model-spec-mlp" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.46</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create model specification</span></span>
<span><span class="va">reg_spec</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">mlp</span><span class="op">(</span>learn_rate <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"brulee"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">reg_spec</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p> </p>
<pre><code>Single Layer Neural Network Model Specification (regression)

Main Arguments:
  learn_rate = tune()

Computational engine: brulee

Model fit template:
brulee::brulee_mlp(x = missing_arg(), y = missing_arg(), learn_rate = tune())</code></pre>
</div>
<p>And include the code in <a href="#exm-predict-reg-mlp-learning-rate" class="quarto-xref">Example&nbsp;<span>9.47</span></a> to create a grid of values for the learning rate hyperparameter, as part of the model building workflow.</p>
<div id="exm-predict-reg-mlp-learning-rate" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.47</strong></span> Tuning values for the learning rate hyperparameter</p>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">reg_grid</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">grid_regular</span><span class="op">(</span><span class="fu">learn_rate</span><span class="op">(</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s collect the metrics and inspect the RMSE and <span class="math inline">\(R^2\)</span> values. The code is seen in <a href="#exm-predict-reg-metrics-mlp" class="quarto-xref">Example&nbsp;<span>9.48</span></a>.</p>
<div id="exm-predict-reg-metrics-mlp" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.48</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb81"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Collect metrics</span></span>
<span><span class="fu">collect_metrics</span><span class="op">(</span><span class="va">reg_mlp_cv</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 6
  .metric .estimator   mean     n std_err .config             
  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
1 rmse    standard   14.7      10  0.951  Preprocessor1_Model1
2 rsq     standard    0.627     9  0.0214 Preprocessor1_Model1</code></pre>
</div>
</div>
</div>
<p>So in summary, we’ve tried four different model specifications. The regularized linear regression model, the decision tree model, the random forest model, and the neural network model. The random forest model performed the best. For each of these models, however, we have only tried word features measured by <span class="math inline">\(tf\)</span>-<span class="math inline">\(idf\)</span>. We could imagine that the performance of these models could be improved by varying the features to include bigrams, for example. We could also explore different measures of word usage. Furthermore, for some of our models, we could try different engines and/ or hyperparameters (some have more than one!).</p>
<p>We could continue to try to explore these possible combinations, and you likely would in your research. But at this point we have a model that is performing better than the null model and is performing better than the other models we have tried. So we will consider this model to be good enough for our purposes.</p>
<p>Let’s take our random forest model, fit it to our training data, apply it to the testing data, and collect the metrics on the test set. The code is seen in <a href="#exm-predict-reg-model-spec-random-forest-workflow-tune-fit" class="quarto-xref">Example&nbsp;<span>9.49</span></a>.</p>
<div id="exm-predict-reg-model-spec-random-forest-workflow-tune-fit" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.49</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb83"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Fit the model to the training set and</span></span>
<span><span class="co"># evaluate on the test set</span></span>
<span><span class="va">reg_final_fit</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">last_fit</span><span class="op">(</span></span>
<span>    <span class="va">reg_wf_rf</span>,</span>
<span>    split <span class="op">=</span> <span class="va">reg_split</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># Evaluate model on testing set</span></span>
<span><span class="fu">collect_metrics</span><span class="op">(</span><span class="va">reg_final_fit</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 4
  .metric .estimator .estimate .config             
  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 rmse    standard      12.9   Preprocessor1_Model1
2 rsq     standard       0.689 Preprocessor1_Model1</code></pre>
</div>
</div>
<p> </p>
</div>
<p>OK. The difference between the cross-validated metrics and the metrics for the test set differ —but only slightly. This suggests that the model is robust and that we have not overfit the data from the training set.</p>
<!-- Step 7: Interpret -->
<p>Now, our likely goal as an academic is to understand something about the features that contribute to the performance of the model. So let’s approach extracting feature importance from the random forest model we build with the <code>ranger</code> engine. Remember, we added an <code>importance</code> argument to the <code>set_engine()</code> function and set it to ‘impurity’. We can now take advantage by using {vip} to extract the feature importance. The code is seen in <a href="#exm-predict-reg-final-fit-vip" class="quarto-xref">Example&nbsp;<span>9.50</span></a>.</p>
<div id="exm-predict-reg-final-fit-vip" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.50</strong></span> &nbsp;</p>
<div class="cell">
<div class="sourceCode" id="cb85"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Extract feature importance</span></span>
<span><span class="va">reg_vip</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">reg_final_fit</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">extract_fit_parsnip</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://koalaverse.github.io/vip/reference/vi.html">vi</a></span><span class="op">(</span>scale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">reg_vip</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 10 × 2
   Variable        Importance
   &lt;chr&gt;                &lt;dbl&gt;
 1 tfidf_text_que       100  
 2 tfidf_text_es         68.8
 3 tfidf_text_una        57.4
 4 tfidf_text_por        57.2
 5 tfidf_text_pero       54.0
 6 tfidf_text_del        48.5
 7 tfidf_text_con        46.1
 8 tfidf_text_se         44.9
 9 tfidf_text_para       44.1
10 tfidf_text_muy        43.6</code></pre>
</div>
</div>
<p> </p>
</div>
<p>We can now visualize the feature importance of the model. The code is seen in <a href="#exm-predict-reg-final-fit-vip-visualize" class="quarto-xref">Example&nbsp;<span>9.51</span></a>.</p>
<div id="exm-predict-reg-final-fit-vip-visualize" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.51</strong></span> &nbsp;</p>
<div class="sourceCode" id="cb87"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Extract predictions</span></span>
<span><span class="va">reg_vip</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>Variable <span class="op">=</span> <span class="fu">str_replace</span><span class="op">(</span><span class="va">Variable</span>, <span class="st">"^tfidf_text_"</span>, <span class="st">""</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_max</span><span class="op">(</span><span class="va">Importance</span>, n <span class="op">=</span> <span class="fl">20</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="co"># reorder variables by importance</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/reorder.factor.html">reorder</a></span><span class="op">(</span><span class="va">Variable</span>, <span class="va">Importance</span><span class="op">)</span>, <span class="va">Importance</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">coord_flip</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Feature"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Importance"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-predict-reg-final-fit-vip-visualize" class="quarto-float quarto-figure quarto-figure-center anchored" alt="A dot plot which shows the importance of the features in the random forest model. The y-axis is the feature (sorted by importance) and the x-axis is the importance value.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-predict-reg-final-fit-vip-visualize-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="9_predict_files/figure-html/fig-predict-reg-final-fit-vip-visualize-1.png" class="img-fluid figure-img" alt="A dot plot which shows the importance of the features in the random forest model. The y-axis is the feature (sorted by importance) and the x-axis is the importance value." width="576">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-predict-reg-final-fit-vip-visualize-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.7: Feature importance of the random forest model
</figcaption></figure>
</div>
</div>
</div>
<p> </p>
<p>In this section, we’ve built text regression models focusing on the ability to change algorithms and hyperparameters. We have also seen some of the differences between evaluating model performance between classification and regression tasks. There are many more combinations of model specifications and feature selection and engineering that can be applied. In your research, you will find yourself using these tools to explore the best model for your data.</p>
</section></section><section id="activities" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="activities">Activities</h2>
<p>In the following activities, we will apply the concepts and techniques we have learned in this chapter. We will use the Tidymodels framework to build and evaluate supervised machine learning models for text classification and regression tasks.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-file-code" aria-label="file-code"></i> Recipe</strong></p>
<p><strong>What</strong>: Building predictive models<br><strong>How</strong>: Read Recipe 9, complete comprehension check, and prepare for Lab 9.<br><strong>Why</strong>: To continue to build experience building predictive models with the Tidymodels framework.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-flask" aria-label="flask"></i> Lab</strong></p>
<p><strong>What</strong>: Text classification<br><strong>How</strong>: Clone, fork, and complete the steps in Lab 9.<br><strong>Why</strong>: To apply your knowledge of supervised machine learning to a text classification task.</p>
</div>
</div>
</div>
</section><section id="summary" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="summary">Summary</h2>
<p>In this chapter, we outlined the workflow for approaching predictive modeling and the Tidymodels framework. We then applied the workflow to text classification and regression tasks. In the process, we gained experience identifying, selecting, and engineering features on the one hand, and building and tuning models on the other. To evaluate the models, we used cross-validation for performance and finalized our interpretation with techniques to extract feature importance.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list" style="display: none">
<div id="ref-Ackoff1989" class="csl-entry" role="listitem">
Ackoff, R. L. (1989). From data to wisdom. <em>Journal of Applied Systems Analysis</em>, <em>16</em>(1), 3–9.
</div>
<div id="ref-Baayen2011" class="csl-entry" role="listitem">
Baayen, R. H. (2011). Corpus linguistics and naive discriminative learning. <em>Revista Brasileira de Lingu<span>í</span>stica Aplicada</em>, <em>11</em>(2), 295–328.
</div>
<div id="ref-Deshors2016" class="csl-entry" role="listitem">
Deshors, S. C., &amp; Gries, S. Th. (2016). Profiling verb complementation constructions across new <span>Englishes</span>. <em>International Journal of Corpus Linguistics.</em>, <em>21</em>(2), 192–218.
</div>
<div id="ref-Gries2014" class="csl-entry" role="listitem">
Gries, S. Th., &amp; Deshors, S. C. (2014). Using regressions to explore deviations between corpus data and a standard/ target: Two suggestions. <em>Corpora</em>, <em>9</em>(1), 109–136. doi:<a href="https://doi.org/10.3366/cor.2014.0053">10.3366/cor.2014.0053</a>
</div>
<div id="ref-R-textrecipes" class="csl-entry" role="listitem">
Hvitfeldt, E. (2023). <em><span class="nocase">textrecipes</span>: Extra recipes for text processing</em>. Retrieved from <a href="https://github.com/tidymodels/textrecipes">https://github.com/tidymodels/textrecipes</a>
</div>
<div id="ref-Lozano2022" class="csl-entry" role="listitem">
Lozano, C. (2022). <span>CEDEL2</span>: <span>Design</span>, compilation and web interface of an online corpus for <span>L2 Spanish</span> acquisition research. <em>Second Language Research</em>, <em>38</em>(4), 965–983. doi:<a href="https://doi.org/10.1177/02676583211050522">10.1177/02676583211050522</a>
</div>
<div id="ref-Rowley2007" class="csl-entry" role="listitem">
Rowley, J. (2007). The wisdom hierarchy: <span>Representations</span> of the <span>DIKW</span> hierarchy. <em>Journal of Information Science</em>, <em>33</em>(2), 163–180. doi:<a href="https://doi.org/10.1177/0165551506070706">10.1177/0165551506070706</a>
</div>
<div id="ref-R-washoku" class="csl-entry" role="listitem">
Uryu, S. (2024). <em><span class="nocase">washoku</span>: Extra ’recipes’ for <span>J</span>apanese text, date and address processing</em>. Retrieved from <a href="https://github.com/uribo/washoku">https://github.com/uribo/washoku</a>
</div>
<div id="ref-Wickham2017" class="csl-entry" role="listitem">
Wickham, H., &amp; Grolemund, G. (2017). <em>R for data science</em> (First edit.). O’Reilly Media. Retrieved from <a href="http://r4ds.had.co.nz/">http://r4ds.had.co.nz/</a>
</div>
</div>
</section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>Note that functions for meta-features require more sophisticated text analysis software to be installed on the computing environment (e.g.&nbsp;{spacyr} for <code><a href="https://textrecipes.tidymodels.org/reference/step_lemma.html">step_lemma()</a></code>, <code>step_pos()</code>, <em>etc.</em>). See {textrecipes} documentation for more information.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>The LASSO (least absolute shrinkage and selection operator) is a type of regularization that penalizes the absolute value of the coefficients. In essence, it smooths the coefficients by shrinking them towards zero to avoid coefficients picking up on particularities of the training data that will not generalize to new data.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../part_4/8_explore.html" class="pagination-link" aria-label="Explore">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Explore</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../part_4/10_infer.html" class="pagination-link" aria-label="Infer">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Infer</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/qtalr/book/blob/main/part_4/9_predict.qmd" target="_blank" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/qtalr/book/edit/main/part_4/9_predict.qmd" target="_blank" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/qtalr/book/issues" target="_blank" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>